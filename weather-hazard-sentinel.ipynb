{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed094b6",
   "metadata": {
    "papermill": {
     "duration": 0.009503,
     "end_time": "2025-11-27T05:19:52.248264",
     "exception": false,
     "start_time": "2025-11-27T05:19:52.238761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weather & Hazard Sentinel: Multi-Agent Monitoring for the Texas Gulf Coast\n",
    "\n",
    "**Track:** Agents for Good (Disaster Response & Preparedness)  \n",
    "**Region:** American Red Cross · Texas Gulf Coast Region  \n",
    "\n",
    "This notebook implements a multi-agent **Weather & Hazard Sentinel** that ingests live weather data, interprets hazard risk, evaluates triggers for readiness, and generates a brief for regional leadership. It is designed for roles like:\n",
    "\n",
    "- Regional Planning & Situational Awareness Manager  \n",
    "- Regional Preparedness Point of Contact (POC)  \n",
    "\n",
    "and supports **situational awareness, early hazard detection, and response posture decisions**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3384910d",
   "metadata": {
    "papermill": {
     "duration": 0.007476,
     "end_time": "2025-11-27T05:19:52.263560",
     "exception": false,
     "start_time": "2025-11-27T05:19:52.256084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Problem · Solution · Value\n",
    "\n",
    "### Problem\n",
    "\n",
    "The Texas Gulf Coast Region faces frequent weather-driven hazards (heavy rain, flooding, heat, severe storms). Right now, situational awareness and readiness decisions often depend on ad-hoc checks of multiple websites, manual reading of discussions, and non-standard notes. This creates three issues:\n",
    "\n",
    "- **Fragmented data:** Forecasts, alerts, and observations live in different tools.  \n",
    "- **Inconsistent triggers:** Readiness decisions vary by person and shift.  \n",
    "- **Limited history:** It is hard to review “what we saw” versus “what actually happened.”\n",
    "\n",
    "### Solution\n",
    "\n",
    "Build a **Weather & Hazard Sentinel** agent system that:\n",
    "\n",
    "1. Pulls **live weather data** for key regional areas (Coastal Bend, Houston Metro, Golden Triangle).  \n",
    "2. Converts this into **structured hazard risks** (hazard type, timeframe, likelihood, impact, rationale).  \n",
    "3. Evaluates these risks against a **rule-based trigger library** to compute a recommended **readiness posture** per area.  \n",
    "4. Generates a **human-readable brief** for regional leadership and logs all results for after-action review.  \n",
    "\n",
    "The system runs as a **loop agent** that can be scheduled (e.g., Cloud Run + Cloud Scheduler) and supports **checkpointing** for long-running operations.\n",
    "\n",
    "### Value\n",
    "\n",
    "For the American Red Cross | Texas Gulf Coast Region, this agent aims to:\n",
    "\n",
    "- Provide a **single, repeatable pipeline** for hazard monitoring and posture decisions.  \n",
    "- Make triggers **explicit and tunable** instead of implicit.  \n",
    "- Preserve a **history of runs, risks, and triggers** for training, after-action reviews, and system improvement.  \n",
    "- Lay the groundwork for **AI-assisted interpretation** of official bulletins in future iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e33aad7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-27T05:19:52.280965Z",
     "iopub.status.busy": "2025-11-27T05:19:52.279995Z",
     "iopub.status.idle": "2025-11-27T05:19:54.412957Z",
     "shell.execute_reply": "2025-11-27T05:19:54.412053Z"
    },
    "papermill": {
     "duration": 2.143938,
     "end_time": "2025-11-27T05:19:54.415030",
     "exception": false,
     "start_time": "2025-11-27T05:19:52.271092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Weather API configured: https://api.openweathermap.org/data/2.5/weather\n"
     ]
    }
   ],
   "source": [
    "# 1. Core imports & basic config\n",
    "\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import datetime as dt\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# REGION CONFIG\n",
    "# -------------------------------------------------------\n",
    "\n",
    "REGION_NAME = \"American Red Cross | Texas Gulf Coast Region\"\n",
    "\n",
    "REGION_AREAS = [\n",
    "    \"Coastal Bend\",\n",
    "    \"Houston Metro\",\n",
    "    \"Golden Triangle\",\n",
    "]\n",
    "\n",
    "# Area coordinates for real API calls\n",
    "REGION_AREA_COORDS = {\n",
    "    \"Coastal Bend\":      {\"lat\": 27.8,  \"lon\": -97.4},\n",
    "    \"Houston Metro\":     {\"lat\": 29.76, \"lon\": -95.37},\n",
    "    \"Golden Triangle\":   {\"lat\": 30.08, \"lon\": -94.13},\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# HAZARD TYPES\n",
    "# -------------------------------------------------------\n",
    "\n",
    "HAZARD_TYPES = [\n",
    "    \"Heavy Rain & Flooding\",\n",
    "    \"Severe Storms\",\n",
    "    \"Excessive Heat\",\n",
    "    \"Wildfire\",\n",
    "]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# TRIGGERS\n",
    "# -------------------------------------------------------\n",
    "\n",
    "TRIGGERS = [\n",
    "    {\n",
    "        \"id\": \"flood_enhanced_monitoring\",\n",
    "        \"hazard\": \"Heavy Rain & Flooding\",\n",
    "        \"min_likelihood\": \"Medium\",\n",
    "        \"min_impact\": \"Disruptive\",\n",
    "        \"recommended_posture\": \"Enhanced Monitoring\",\n",
    "        \"name\": \"Heavy Rain – Flash Flood Watch\",\n",
    "        \"note\": \"Consider readiness actions for flood-prone areas.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"flood_response_consideration\",\n",
    "        \"hazard\": \"Heavy Rain & Flooding\",\n",
    "        \"min_likelihood\": \"High\",\n",
    "        \"min_impact\": \"Dangerous\",\n",
    "        \"recommended_posture\": \"Response Consideration\",\n",
    "        \"name\": \"Heavy Rain – Possible Flash Flooding\",\n",
    "        \"note\": \"Discuss shelter readiness and resource pre-positioning.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "LIKELIHOOD_ORDER = [\"Low\", \"Medium\", \"High\"]\n",
    "IMPACT_ORDER = [\"Nuisance\", \"Disruptive\", \"Dangerous\"]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# LOAD ALL SECRETS (Kaggle → env vars)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "# Weather API (OpenWeather \"Current Weather\" FREE endpoint)\n",
    "WEATHER_API_KEY = user_secrets.get_secret(\"WEATHER_API_KEY\")\n",
    "WEATHER_API_URL = user_secrets.get_secret(\"WEATHER_API_URL\")\n",
    "\n",
    "# If user did not set WEATHER_API_URL secret, fallback:\n",
    "if not WEATHER_API_URL:\n",
    "    WEATHER_API_URL = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "os.environ[\"WEATHER_API_KEY\"] = WEATHER_API_KEY\n",
    "os.environ[\"WEATHER_API_URL\"] = WEATHER_API_URL\n",
    "\n",
    "logging.info(f\"Weather API configured: {WEATHER_API_URL}\")\n",
    "\n",
    "# Gemini API key\n",
    "GEMINI_API_KEY = user_secrets.get_secret(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
    "\n",
    "# Optional:\n",
    "GCP_PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\", \"\")\n",
    "GCS_BUCKET = os.getenv(\"GCS_BUCKET\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0043a0c3",
   "metadata": {
    "papermill": {
     "duration": 0.00793,
     "end_time": "2025-11-27T05:19:54.431092",
     "exception": false,
     "start_time": "2025-11-27T05:19:54.423162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Architecture Overview: “Weather & Hazard Sentinel”\n",
    "\n",
    "The system is implemented as a **multi-agent pipeline**:\n",
    "\n",
    "**Data Sources → Tools → Agents → A2A Messages → Memory & Checkpoint → Outputs**\n",
    "\n",
    "### Core Data Flow (One Monitoring Cycle)\n",
    "\n",
    "1. **Data Ingestion Agent**  \n",
    "   - Calls the OpenWeather “Current Weather” API for each area.  \n",
    "   - Produces a `HazardInputsMessage` with structured forecast slices (e.g., QPF proxy, feels-like temperature) and short bulletins.\n",
    "\n",
    "2. **Hazard Interpretation Agent**  \n",
    "   - Reads `HazardInputsMessage`.  \n",
    "   - Uses **rule-based thresholds** (and optionally Gemini) to assign **likelihood** and **impact** per hazard.  \n",
    "   - Produces a `HazardRisksMessage` containing a list of `HazardRisk` objects.\n",
    "\n",
    "3. **Trigger Evaluation Agent**  \n",
    "   - Compares each `HazardRisk` with a configurable **Trigger Library**.  \n",
    "   - Computes a recommended **readiness posture** per area (Normal, Enhanced Monitoring, Response Consideration).  \n",
    "   - Produces a `TriggerResultsMessage`.\n",
    "\n",
    "4. **Briefing Agent**  \n",
    "   - Takes `HazardRisksMessage` + `TriggerResultsMessage`.  \n",
    "   - Generates a concise **Weather & Hazard Brief** for regional leadership (via Gemini when available, with a non-LLM fallback).  \n",
    "   - Produces a `BriefPacketMessage`.\n",
    "\n",
    "5. **Memory & Logging Agent**  \n",
    "   - Logs runs, risks, triggers, and briefs into in-memory tables (convertible to DataFrames).  \n",
    "   - Maintains a `CheckpointState` (last run time, last posture per area, last run ID, operational period label).\n",
    "\n",
    "6. **Orchestrator / Scheduler**  \n",
    "   - Coordinates the entire cycle: **Ingestion → Interpretation → Trigger Evaluation → Briefing → Memory**.  \n",
    "   - Supports **pause / resume** and is designed to be called by a **Cloud Run + Cloud Scheduler** job in production.\n",
    "\n",
    "### Agent-to-Agent (A2A) Protocol\n",
    "\n",
    "Agents exchange **typed messages** instead of raw dicts. This makes the system explicit and testable:\n",
    "\n",
    "- `HazardInputsMessage` → from Data Ingestion to Hazard Interpretation  \n",
    "- `HazardRisksMessage` → from Hazard Interpretation to Trigger Evaluation  \n",
    "- `TriggerResultsMessage` → from Trigger Evaluation to Briefing  \n",
    "- `BriefPacketMessage` → from Briefing to Memory / outputs  \n",
    "\n",
    "Each message carries key fields like `area`, `hazard`, `timeframe`, `likelihood`, `impact`, `posture`, `rationale`, and `timestamp`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e82a0",
   "metadata": {
    "papermill": {
     "duration": 0.009228,
     "end_time": "2025-11-27T05:19:54.448514",
     "exception": false,
     "start_time": "2025-11-27T05:19:54.439286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### System Architecture — Weather & Hazard Sentinel\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Source[\"External Weather APIs\\nOpenWeather / NOAA\"]\n",
    "    Ingest[\"Data Ingestion Agent\"]\n",
    "    HazInt[\"Hazard Interpretation Agent\\nRules + Optional Gemini\"]\n",
    "    Trigger[\"Trigger Evaluation Agent\\nThreshold Rules\"]\n",
    "    Brief[\"Briefing Agent\\nLLM / Fallback\"]\n",
    "    Memory[\"Memory & Logging Agent\"]\n",
    "    Checkpt[\"GCS Checkpoint\\nCloud Run Persistence\"]\n",
    "    Output[\"Daily Hazard Brief\\nReadiness Posture\"]\n",
    "\n",
    "    Source --> Ingest\n",
    "    Ingest --> HazInt\n",
    "    HazInt --> Trigger\n",
    "    Trigger --> Brief\n",
    "    Brief --> Memory\n",
    "    Memory --> Checkpt\n",
    "    Brief --> Output\n",
    "\n",
    "    subgraph Runtime\n",
    "        Ingest\n",
    "        HazInt\n",
    "        Trigger\n",
    "        Brief\n",
    "        Memory\n",
    "        Checkpt\n",
    "    end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a23c525",
   "metadata": {
    "papermill": {
     "duration": 0.00777,
     "end_time": "2025-11-27T05:19:54.464236",
     "exception": false,
     "start_time": "2025-11-27T05:19:54.456466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Capstone Features (How This Maps to the Rubric)\n",
    "\n",
    "This project demonstrates multiple concepts from the course:\n",
    "\n",
    "- **Multi-Agent System**\n",
    "  - Data Ingestion Agent (`DataIngestionAgent`)\n",
    "  - Hazard Interpretation Agent (`HazardInterpretationAgent`)\n",
    "  - Trigger Evaluation Agent (`TriggerEvaluationAgent`)\n",
    "  - Briefing Agent (`BriefingAgent`)\n",
    "  - Memory & Logging Agent (`MemoryLoggingAgent`)\n",
    "  - Orchestrator / Scheduler (`OrchestratorScheduler`)\n",
    "\n",
    "- **Tools**\n",
    "  - External HTTP tool: **OpenWeather Current Weather API** (real live data).\n",
    "  - LLM tool: **Gemini API** via `google-generativeai` (used for hazard refinement and briefing, with fallback).\n",
    "\n",
    "- **Sessions & Memory**\n",
    "  - `MemoryLoggingAgent` stores:\n",
    "    - Runs (`runs`)\n",
    "    - Risks (`risks_log`)\n",
    "    - Fired triggers (`triggers_log`)\n",
    "    - Briefs (`briefs_log`)\n",
    "  - `CheckpointState` tracks:\n",
    "    - `last_run_time`\n",
    "    - `last_posture_by_area`\n",
    "    - `last_run_id`\n",
    "    - `operational_period_label`\n",
    "\n",
    "- **Long-Running Operations**\n",
    "  - `OrchestratorScheduler.run_cycle()` represents a **single monitoring cycle**.  \n",
    "  - A separate `orchestrator_cloud_run_cycle()` (later cell) wraps this with **GCS checkpoint load/save**, suitable for **Cloud Run + Cloud Scheduler**.\n",
    "\n",
    "These pieces together show a practical, cloud-ready **Weather & Hazard Sentinel** agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e821c95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:19:54.481952Z",
     "iopub.status.busy": "2025-11-27T05:19:54.480994Z",
     "iopub.status.idle": "2025-11-27T05:19:54.494009Z",
     "shell.execute_reply": "2025-11-27T05:19:54.493217Z"
    },
    "papermill": {
     "duration": 0.023741,
     "end_time": "2025-11-27T05:19:54.495555",
     "exception": false,
     "start_time": "2025-11-27T05:19:54.471814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. A2A message dataclasses (schemas for agent-to-agent messages)\n",
    "\n",
    "@dataclass\n",
    "class HazardInputsMessage:\n",
    "    \"\"\"\n",
    "    A2A: from Data Ingestion Agent → Hazard Interpretation Agent.\n",
    "    Represents raw hazard inputs for a given run.\n",
    "    \"\"\"\n",
    "    run_id: str\n",
    "    as_of: dt.datetime\n",
    "    areas: List[str]\n",
    "    forecasts: List[Dict[str, Any]]   # structured forecast slices\n",
    "    bulletins: List[str]              # free-text text products\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HazardRisk:\n",
    "    \"\"\"\n",
    "    Internal representation for a single hazard risk in an area.\n",
    "    \"\"\"\n",
    "    area: str\n",
    "    hazard: str\n",
    "    timeframe: str\n",
    "    likelihood: str      # Low / Medium / High\n",
    "    impact: str          # Nuisance / Disruptive / Dangerous\n",
    "    rationale: str\n",
    "    supporting_evidence: List[str]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HazardRisksMessage:\n",
    "    \"\"\"\n",
    "    A2A: from Hazard Interpretation → Trigger Evaluation Agent.\n",
    "    \"\"\"\n",
    "    run_id: str\n",
    "    as_of: dt.datetime\n",
    "    risks: List[HazardRisk]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AreaTriggerSummary:\n",
    "    \"\"\"\n",
    "    Structured summary of posture + triggers for a given area.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    posture: str\n",
    "    fired_triggers: List[Dict[str, Any]]  # name, rationale, trigger_id\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TriggerResultsMessage:\n",
    "    \"\"\"\n",
    "    A2A: from Trigger Evaluation → Briefing Agent.\n",
    "    \"\"\"\n",
    "    run_id: str\n",
    "    as_of: dt.datetime\n",
    "    areas: List[AreaTriggerSummary]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BriefPacketMessage:\n",
    "    \"\"\"\n",
    "    A2A: from Briefing Agent → Memory / Outputs.\n",
    "    \"\"\"\n",
    "    run_id: str\n",
    "    as_of: dt.datetime\n",
    "    markdown_brief: str\n",
    "    text_brief: str\n",
    "    posture_overview: Dict[str, str]  # area → posture\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CheckpointState:\n",
    "    \"\"\"\n",
    "    For long-running operations (pause/resume in Cloud Run / scheduler).\n",
    "    \"\"\"\n",
    "    last_run_time: Optional[dt.datetime]\n",
    "    last_posture_by_area: Dict[str, str]\n",
    "    last_run_id: Optional[str]\n",
    "    operational_period_label: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efbf83",
   "metadata": {
    "papermill": {
     "duration": 0.007627,
     "end_time": "2025-11-27T05:19:54.511115",
     "exception": false,
     "start_time": "2025-11-27T05:19:54.503488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Agent-to-Agent (A2A) Message Flow\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant Ingest as Data Ingestion Agent\n",
    "    participant HazInt as Hazard Interpretation Agent\n",
    "    participant Trigger as Trigger Evaluation Agent\n",
    "    participant Brief as Briefing Agent\n",
    "    participant Mem as Memory & Logging Agent\n",
    "\n",
    "    Ingest->>HazInt: HazardInputsMessage\n",
    "    HazInt->>Trigger: HazardRisksMessage\n",
    "    Trigger->>Brief: TriggerResultsMessage\n",
    "    Brief->>Mem: BriefPacketMessage\n",
    "    Mem-->>Mem: Update CheckpointState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b21acf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:19:54.528664Z",
     "iopub.status.busy": "2025-11-27T05:19:54.528006Z",
     "iopub.status.idle": "2025-11-27T05:20:05.696980Z",
     "shell.execute_reply": "2025-11-27T05:20:05.696095Z"
    },
    "papermill": {
     "duration": 11.179946,
     "end_time": "2025-11-27T05:20:05.698621",
     "exception": false,
     "start_time": "2025-11-27T05:19:54.518675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Gemini client configured successfully.\n"
     ]
    }
   ],
   "source": [
    "# CELL 3 — Gemini client setup (official Python client, external LLM calls)\n",
    "\n",
    "!pip install -q google-generativeai\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "# Load key from Kaggle Secrets and export as env var\n",
    "GEMINI_API_KEY = user_secrets.get_secret(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "\n",
    "    if GEMINI_API_KEY and len(GEMINI_API_KEY) > 0:\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        logging.info(\"Gemini client configured successfully.\")\n",
    "    else:\n",
    "        logging.warning(\"GEMINI_API_KEY not set or empty. Gemini calls will be mocked.\")\n",
    "except Exception as e:\n",
    "    logging.warning(f\"Could not import google-generativeai: {e}\")\n",
    "    genai = None\n",
    "\n",
    "# Use a current, supported model (you can override via env var GEMINI_MODEL)\n",
    "DEFAULT_GEMINI_MODEL = os.getenv(\"GEMINI_MODEL\", \"gemini-2.5-pro\")\n",
    "\n",
    "\n",
    "def call_gemini(\n",
    "    prompt: str,\n",
    "    model_name: str = DEFAULT_GEMINI_MODEL,\n",
    "    temperature: float = 0.2,\n",
    "    max_output_tokens: int = 768,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Safely call Gemini.\n",
    "\n",
    "    - Handles missing API key / client errors\n",
    "    - Extracts text from candidates instead of using response.text\n",
    "    - On error, returns a tagged string so callers can decide to fallback\n",
    "    \"\"\"\n",
    "\n",
    "    if not genai or not GEMINI_API_KEY:\n",
    "        logging.warning(\"Gemini not configured; returning fallback.\")\n",
    "        return \"[Gemini fallback: key missing or not loaded] \" + prompt[:200]\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                temperature=temperature,\n",
    "                max_output_tokens=max_output_tokens,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Try to extract text from the first candidate\n",
    "        try:\n",
    "            if getattr(response, \"candidates\", None):\n",
    "                parts = response.candidates[0].content.parts\n",
    "                text = \"\".join(getattr(p, \"text\", \"\") for p in parts)\n",
    "                if text and text.strip():\n",
    "                    return text\n",
    "        except Exception as inner_e:\n",
    "            logging.warning(f\"Could not extract text from Gemini response: {inner_e}\")\n",
    "\n",
    "        # Fallback: short stringified response for debugging\n",
    "        return \"[Gemini raw response] \" + str(response)[:500]\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Gemini call failed: {e}\")\n",
    "        return f\"[Gemini error: {e}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3616bcca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:05.717137Z",
     "iopub.status.busy": "2025-11-27T05:20:05.716032Z",
     "iopub.status.idle": "2025-11-27T05:20:05.724189Z",
     "shell.execute_reply": "2025-11-27T05:20:05.723263Z"
    },
    "papermill": {
     "duration": 0.018833,
     "end_time": "2025-11-27T05:20:05.725679",
     "exception": false,
     "start_time": "2025-11-27T05:20:05.706846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. External weather API helper (OpenWeather current weather endpoint)\n",
    "\n",
    "import requests\n",
    "\n",
    "def fetch_weather_raw(\n",
    "    lat: float,\n",
    "    lon: float,\n",
    "    units: str = \"metric\",\n",
    "    api_url: Optional[str] = None,\n",
    "    api_key: Optional[str] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch current weather from OpenWeather 'Current Weather' endpoint.\n",
    "\n",
    "    Default:\n",
    "      https://api.openweathermap.org/data/2.5/weather\n",
    "\n",
    "    It returns fields like:\n",
    "      - main.temp\n",
    "      - main.feels_like\n",
    "      - rain[\"1h\"] (mm) if raining\n",
    "      - etc.\n",
    "    \"\"\"\n",
    "    if api_url is None:\n",
    "        api_url = WEATHER_API_URL\n",
    "    if api_key is None:\n",
    "        api_key = WEATHER_API_KEY\n",
    "\n",
    "    if not api_url or not api_key:\n",
    "        logging.warning(\"Weather API not configured; returning empty response.\")\n",
    "        return {}\n",
    "\n",
    "    params = {\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon,\n",
    "        \"units\": units,\n",
    "        \"appid\": api_key,   # OpenWeather uses 'appid'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(api_url, params=params, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        logging.info(\"Weather API call OK.\")\n",
    "        return resp.json()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Weather API call failed: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29287565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:05.744046Z",
     "iopub.status.busy": "2025-11-27T05:20:05.743096Z",
     "iopub.status.idle": "2025-11-27T05:20:05.748549Z",
     "shell.execute_reply": "2025-11-27T05:20:05.747667Z"
    },
    "papermill": {
     "duration": 0.016205,
     "end_time": "2025-11-27T05:20:05.750007",
     "exception": false,
     "start_time": "2025-11-27T05:20:05.733802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Region locations / mapping (example lat/lon per area)\n",
    "\n",
    "# You can refine these with real coordinates for your region.\n",
    "REGION_AREA_COORDS = {\n",
    "    \"Coastal Bend\": {\"lat\": 27.8, \"lon\": -97.4},      # Corpus Christi-ish\n",
    "    \"Houston Metro\": {\"lat\": 29.76, \"lon\": -95.37},   # Houston\n",
    "    \"Golden Triangle\": {\"lat\": 30.08, \"lon\": -94.13}, # Beaumont/Port Arthur area\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9929e1a",
   "metadata": {
    "papermill": {
     "duration": 0.007982,
     "end_time": "2025-11-27T05:20:05.765968",
     "exception": false,
     "start_time": "2025-11-27T05:20:05.757986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Agents in Detail\n",
    "\n",
    "### 4.1 Data Ingestion Agent (`DataIngestionAgent`) · Cell 6\n",
    "\n",
    "- Input: list of region areas (Coastal Bend, Houston Metro, Golden Triangle).  \n",
    "- Tool: OpenWeather **Current Weather** API (lat, lon → JSON).  \n",
    "- Logic:\n",
    "  - Extracts:\n",
    "    - `temp`, `feels_like` (°C)\n",
    "    - `rain[\"1h\"]` / `rain[\"3h\"]` (mm) if present\n",
    "  - Computes:\n",
    "    - `qpf_inches_24h` as a simple proxy for heavy rain  \n",
    "  - Maps to hazard slices:\n",
    "    - `Heavy Rain & Flooding` if QPF proxy ≥ threshold  \n",
    "    - `Excessive Heat` if feels_like ≥ threshold  \n",
    "    - `No Significant Hazard` otherwise\n",
    "  - Optional **demo override** (`demo_force_hazard=True`) forces a heavy rain case for Coastal Bend to clearly demonstrate trigger firing.\n",
    "\n",
    "- Output: `HazardInputsMessage` with:\n",
    "  - `forecasts`: list of per-area hazard slices  \n",
    "  - `bulletins`: short operational summaries (no LLM usage, to conserve quota)\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 Hazard Interpretation Agent (`HazardInterpretationAgent`) · Cell 7\n",
    "\n",
    "- Input: `HazardInputsMessage`.  \n",
    "- Logic:\n",
    "  - `_rule_based_seed()`:\n",
    "    - Uses thresholds on `qpf_inches_24h` (rain) and `heat_index` (heat) to assign:\n",
    "      - `likelihood ∈ {Low, Medium, High}`\n",
    "      - `impact ∈ {Nuisance, Disruptive, Dangerous}`\n",
    "    - Generates a short quantitative `rationale`.\n",
    "  - `_refine_with_gemini()` (optional):\n",
    "    - Sends forecast + bulletins + seed assessment to Gemini.\n",
    "    - Asks for a strict JSON response (`likelihood`, `impact`, `rationale`).\n",
    "    - Tries to parse and override the rule-based values.\n",
    "\n",
    "- Output: `HazardRisksMessage` (list of `HazardRisk` objects).  \n",
    "- In this notebook run, `use_gemini=False` to avoid quota limits, but the LLM refinement path is implemented and ready.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3 Trigger Evaluation Agent (`TriggerEvaluationAgent`) · Cell 8\n",
    "\n",
    "- Input: `HazardRisksMessage`.  \n",
    "- Logic:\n",
    "  - Compares each `HazardRisk` to a **Trigger Library** defined in `TRIGGERS`.  \n",
    "  - Each trigger specifies:\n",
    "    - `hazard`\n",
    "    - `min_likelihood`\n",
    "    - `min_impact`\n",
    "    - `recommended_posture`\n",
    "  - Uses ordered scales:\n",
    "    - `LIKELIHOOD_ORDER = [\"Low\", \"Medium\", \"High\"]`\n",
    "    - `IMPACT_ORDER = [\"Nuisance\", \"Disruptive\", \"Dangerous\"]`\n",
    "  - For each area:\n",
    "    - Starts at `Normal`.\n",
    "    - Upgrades to `Enhanced Monitoring` or `Response Consideration` if any trigger’s conditions are met.\n",
    "    - Records `fired_triggers` with name and rationale.\n",
    "\n",
    "- Output: `TriggerResultsMessage` with `areas: List[AreaTriggerSummary]`.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.4 Briefing Agent (`BriefingAgent`) · Cell 9\n",
    "\n",
    "- Input: `HazardRisksMessage` + `TriggerResultsMessage`.  \n",
    "- Logic:\n",
    "  - Builds a compact JSON summary of:\n",
    "    - Region name, timestamp  \n",
    "    - All hazards per area  \n",
    "    - Posture and fired triggers per area\n",
    "  - If `use_gemini=True` and an API key is available:\n",
    "    - Calls Gemini with a prompt to generate a brief with:\n",
    "      1. Overview  \n",
    "      2. Key Hazards by Area  \n",
    "      3. Recommended Readiness Posture  \n",
    "    - If Gemini returns an error or raw dump, falls back.\n",
    "  - Fallback:\n",
    "    - Generates a plain-text brief style summary that is deterministic and quota-free.\n",
    "\n",
    "- Output: `BriefPacketMessage` with:\n",
    "  - `markdown_brief`\n",
    "  - `text_brief`\n",
    "  - `posture_overview` (area → posture)\n",
    "\n",
    "---\n",
    "\n",
    "### 4.5 Memory & Logging Agent (`MemoryLoggingAgent`) · Cell 10\n",
    "\n",
    "- Input per cycle: `HazardInputsMessage`, `HazardRisksMessage`, `TriggerResultsMessage`, `BriefPacketMessage`.  \n",
    "- Responsibilities:\n",
    "  - Append to:\n",
    "    - `runs` (one row per cycle)\n",
    "    - `risks_log` (one row per hazard risk)\n",
    "    - `triggers_log` (one row per fired trigger)\n",
    "    - `briefs_log` (one row per brief text)\n",
    "  - Update `checkpoint`:\n",
    "    - `last_run_time`\n",
    "    - `last_posture_by_area`\n",
    "    - `last_run_id`\n",
    "    - `operational_period_label`\n",
    "\n",
    "- Output: `to_dataframes()` helper to inspect everything as pandas DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.6 Orchestrator / Scheduler (`OrchestratorScheduler`) · Cell 11\n",
    "\n",
    "- Coordinates the multi-agent pipeline.  \n",
    "- `run_cycle(...)` implements:\n",
    "  1. Data Ingestion → `HazardInputsMessage`\n",
    "  2. Hazard Interpretation → `HazardRisksMessage`\n",
    "  3. Trigger Evaluation → `TriggerResultsMessage`\n",
    "  4. Briefing → `BriefPacketMessage`\n",
    "  5. Memory Logging → checkpoint update  \n",
    "\n",
    "- Supports `pause()` and `resume()` to conceptually illustrate **long-running jobs** where a scheduler can stop and restart runs over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deade909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:05.783788Z",
     "iopub.status.busy": "2025-11-27T05:20:05.783361Z",
     "iopub.status.idle": "2025-11-27T05:20:05.797776Z",
     "shell.execute_reply": "2025-11-27T05:20:05.796763Z"
    },
    "papermill": {
     "duration": 0.025909,
     "end_time": "2025-11-27T05:20:05.799658",
     "exception": false,
     "start_time": "2025-11-27T05:20:05.773749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6. Data Ingestion Agent (OpenWeather current weather → hazard_inputs)\n",
    "\n",
    "class DataIngestionAgent:\n",
    "    \"\"\"\n",
    "    Data Ingestion Agent:\n",
    "      - Calls OpenWeather current weather API for each area.\n",
    "      - Builds HazardInputsMessage with simple hazard slices + bulletins.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, region_areas: List[str]):\n",
    "        self.region_areas = region_areas\n",
    "\n",
    "    def ingest(\n",
    "        self,\n",
    "        time_window: str = \"next_24_hours\",\n",
    "        products: Optional[List[str]] = None,\n",
    "        demo_force_hazard: bool = False,\n",
    "    ) -> HazardInputsMessage:\n",
    "        if products is None:\n",
    "            products = [\"openweather_current\"]\n",
    "\n",
    "        run_id = str(uuid.uuid4())\n",
    "        now = dt.datetime.utcnow()\n",
    "\n",
    "        forecasts: List[Dict[str, Any]] = []\n",
    "        bulletins: List[str] = []\n",
    "\n",
    "        for area in self.region_areas:\n",
    "            coords = REGION_AREA_COORDS.get(area)\n",
    "            if not coords:\n",
    "                continue\n",
    "\n",
    "            raw = fetch_weather_raw(coords[\"lat\"], coords[\"lon\"])\n",
    "            if not raw:\n",
    "                forecasts.append({\n",
    "                    \"area\": area,\n",
    "                    \"hazard\": \"Unknown\",\n",
    "                    \"timeframe\": time_window,\n",
    "                    \"products\": products,\n",
    "                })\n",
    "                bulletins.append(\n",
    "                    f\"{area}: Unable to retrieve external weather data at this time.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # --- Extract simple hazard features from /data/2.5/weather ---\n",
    "            main = raw.get(\"main\", {})\n",
    "            temp = float(main.get(\"temp\", 0.0))\n",
    "            feels_like = float(main.get(\"feels_like\", temp))\n",
    "            rain_mm = 0.0\n",
    "            if \"rain\" in raw:\n",
    "                # can be {\"1h\": mm} or {\"3h\": mm}\n",
    "                rain = raw[\"rain\"]\n",
    "                rain_mm = float(rain.get(\"1h\", rain.get(\"3h\", 0.0)))\n",
    "\n",
    "            # Convert mm to inches for QPF proxy\n",
    "            qpf_inches_24h = rain_mm / 25.4 if rain_mm else 0.0\n",
    "            \n",
    "            hazards_here = []\n",
    "\n",
    "            # Heavy Rain & Flooding proxy\n",
    "            if qpf_inches_24h >= 0.1:\n",
    "                hazards_here.append({\n",
    "                    \"area\": area,\n",
    "                    \"hazard\": \"Heavy Rain & Flooding\",\n",
    "                    \"qpf_inches_24h\": qpf_inches_24h,\n",
    "                    \"timeframe\": \"Next 6–24 hours\",\n",
    "                    \"products\": products,\n",
    "                })\n",
    "\n",
    "            # Excessive Heat proxy using feels_like\n",
    "            if feels_like >= 35.0:  # Celsius\n",
    "                hi = feels_like * 1.1  # crude surrogate\n",
    "                hazards_here.append({\n",
    "                    \"area\": area,\n",
    "                    \"hazard\": \"Excessive Heat\",\n",
    "                    \"heat_index\": hi,\n",
    "                    \"timeframe\": \"Afternoon\",\n",
    "                    \"products\": products,\n",
    "                })\n",
    "\n",
    "            if not hazards_here:\n",
    "                hazards_here.append({\n",
    "                    \"area\": area,\n",
    "                    \"hazard\": \"No Significant Hazard\",\n",
    "                    \"timeframe\": time_window,\n",
    "                    \"products\": products,\n",
    "                })\n",
    "\n",
    "            # --- DEMO OVERRIDE (for capstone video) ----------------------\n",
    "            # If demo_force_hazard=True, force a heavy rain scenario\n",
    "            # for Coastal Bend so triggers clearly fire.\n",
    "            if demo_force_hazard and area == \"Coastal Bend\":\n",
    "                hazards_here = [{\n",
    "                    \"area\": area,\n",
    "                    \"hazard\": \"Heavy Rain & Flooding\",\n",
    "                    \"qpf_inches_24h\": 3.2,   # > 3.0 → High & Dangerous in rules\n",
    "                    \"timeframe\": \"Next 24 hours\",\n",
    "                    \"products\": products + [\"demo_override\"],\n",
    "                }]\n",
    "            # --------------------------------------------------------------\n",
    "            \n",
    "            forecasts.extend(hazards_here)\n",
    "\n",
    "            # Simple rule-based bulletin without LLM (saves quota)\n",
    "            summary_text = (\n",
    "                f\"Current temp {temp:.1f}°C (feels like {feels_like:.1f}°C), \"\n",
    "                f\"rain last hour {rain_mm:.1f} mm. \"\n",
    "            )\n",
    "            \n",
    "            if hazards_here and hazards_here[0][\"hazard\"] != \"No Significant Hazard\":\n",
    "                summary_text += \"Potential operational impacts due to highlighted hazards.\"\n",
    "            else:\n",
    "                summary_text += \"No significant hazards detected at this time.\"\n",
    "            \n",
    "            bulletins.append(f\"{area}: {summary_text}\")\n",
    "\n",
    "        return HazardInputsMessage(\n",
    "            run_id=run_id,\n",
    "            as_of=now,\n",
    "            areas=self.region_areas,\n",
    "            forecasts=forecasts,\n",
    "            bulletins=bulletins,\n",
    "        )\n",
    "\n",
    "\n",
    "ingestion_agent = DataIngestionAgent(REGION_AREAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0063d8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:05.818470Z",
     "iopub.status.busy": "2025-11-27T05:20:05.818084Z",
     "iopub.status.idle": "2025-11-27T05:20:05.834580Z",
     "shell.execute_reply": "2025-11-27T05:20:05.833525Z"
    },
    "papermill": {
     "duration": 0.027808,
     "end_time": "2025-11-27T05:20:05.836263",
     "exception": false,
     "start_time": "2025-11-27T05:20:05.808455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELL 7 — Hazard Interpretation Agent using Gemini (LLM risk analysis)\n",
    "\n",
    "class HazardInterpretationAgent:\n",
    "    \"\"\"\n",
    "    Hazard Interpretation Agent\n",
    "\n",
    "    Responsibilities:\n",
    "    - Read HazardInputsMessage (forecasts + bulletins).\n",
    "    - Use simple rules to seed likelihood/impact.\n",
    "    - Optionally refine that assessment with Gemini based on text/bulletins.\n",
    "    - Output a HazardRisksMessage (A2A: hazard_risks).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, use_gemini: bool = True):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        use_gemini : bool\n",
    "            If True, try to refine rule-based assessments with Gemini.\n",
    "            If False, use rule-based seeds only (no external LLM calls).\n",
    "        \"\"\"\n",
    "        self.use_gemini = use_gemini\n",
    "\n",
    "    def _rule_based_seed(self, fc: Dict[str, Any]) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Simple rule-based seeds for likelihood / impact.\n",
    "        LLM can refine/confirm this.\n",
    "\n",
    "        Returns a dict with fields: likelihood, impact, rationale.\n",
    "        \"\"\"\n",
    "        hazard = fc.get(\"hazard\", \"Unknown\")\n",
    "\n",
    "        if hazard == \"Heavy Rain & Flooding\":\n",
    "            qpf = float(fc.get(\"qpf_inches_24h\", 0.0))\n",
    "            if qpf >= 3.0:\n",
    "                return {\"likelihood\": \"High\", \"impact\": \"Dangerous\", \"rationale\": f\"QPF={qpf:.2f} in/24h.\"}\n",
    "            elif qpf >= 1.5:\n",
    "                return {\"likelihood\": \"Medium\", \"impact\": \"Disruptive\", \"rationale\": f\"QPF={qpf:.2f} in/24h.\"}\n",
    "            elif qpf >= 0.5:\n",
    "                return {\"likelihood\": \"Low\", \"impact\": \"Nuisance\", \"rationale\": f\"QPF={qpf:.2f} in/24h.\"}\n",
    "            else:\n",
    "                return {\"likelihood\": \"Low\", \"impact\": \"Nuisance\", \"rationale\": \"Minimal QPF.\"}\n",
    "\n",
    "        if hazard == \"Excessive Heat\":\n",
    "            hi = float(fc.get(\"heat_index\", 0.0))\n",
    "            if hi >= 108:\n",
    "                return {\"likelihood\": \"High\", \"impact\": \"Dangerous\", \"rationale\": f\"Heat index={hi:.1f}.\"}\n",
    "            elif hi >= 103:\n",
    "                return {\"likelihood\": \"Medium\", \"impact\": \"Disruptive\", \"rationale\": f\"Heat index={hi:.1f}.\"}\n",
    "            elif hi >= 95:\n",
    "                return {\"likelihood\": \"Low\", \"impact\": \"Nuisance\", \"rationale\": f\"Heat index={hi:.1f}.\"}\n",
    "            else:\n",
    "                return {\"likelihood\": \"Low\", \"impact\": \"Nuisance\", \"rationale\": \"Heat not critical.\"}\n",
    "\n",
    "        if hazard == \"No Significant Hazard\":\n",
    "            return {\n",
    "                \"likelihood\": \"Low\",\n",
    "                \"impact\": \"Nuisance\",\n",
    "                \"rationale\": \"No significant hazard indicated.\",\n",
    "            }\n",
    "\n",
    "        # Fallback for unknown hazards\n",
    "        return {\n",
    "            \"likelihood\": \"Low\",\n",
    "            \"impact\": \"Nuisance\",\n",
    "            \"rationale\": \"Default / unknown hazard.\",\n",
    "        }\n",
    "\n",
    "    def _refine_with_gemini(\n",
    "        self,\n",
    "        fc: Dict[str, Any],\n",
    "        seed: Dict[str, str],\n",
    "        bulletins: List[str],\n",
    "    ) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Optional refinement of likelihood/impact using Gemini.\n",
    "        Returns the same schema as seed: likelihood, impact, rationale.\n",
    "        \"\"\"\n",
    "        if not self.use_gemini:\n",
    "            return seed\n",
    "\n",
    "        joined_bulletins = \"\\n\".join(bulletins)\n",
    "        prompt = (\n",
    "            \"You are an emergency management hazard analyst. \"\n",
    "            \"Given the forecast slice and seed assessment below, \"\n",
    "            \"decide if the likelihood and impact need to be adjusted. \"\n",
    "            \"Respond in strict JSON with fields: likelihood, impact, rationale.\\n\\n\"\n",
    "            f\"Forecast slice:\\n{json.dumps(fc)}\\n\\n\"\n",
    "            f\"Seed assessment:\\n{json.dumps(seed)}\\n\\n\"\n",
    "            f\"Relevant bulletins:\\n{joined_bulletins[:3000]}\"\n",
    "        )\n",
    "\n",
    "        raw = call_gemini(prompt, max_output_tokens=384)\n",
    "\n",
    "        # Try to parse JSON from the LLM; if fails, just return seed.\n",
    "        try:\n",
    "            start = raw.find(\"{\")\n",
    "            end = raw.rfind(\"}\")\n",
    "            if start != -1 and end != -1:\n",
    "                j = json.loads(raw[start:end + 1])\n",
    "                likelihood = j.get(\"likelihood\", seed[\"likelihood\"])\n",
    "                impact = j.get(\"impact\", seed[\"impact\"])\n",
    "                rationale = j.get(\"rationale\", seed[\"rationale\"])\n",
    "                return {\n",
    "                    \"likelihood\": likelihood,\n",
    "                    \"impact\": impact,\n",
    "                    \"rationale\": rationale,\n",
    "                }\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not parse Gemini hazard refinement: {e}\")\n",
    "\n",
    "        return seed\n",
    "\n",
    "    def assess(self, inputs_msg: HazardInputsMessage) -> HazardRisksMessage:\n",
    "        \"\"\"\n",
    "        Public interface used by the orchestrator.\n",
    "        \"\"\"\n",
    "        risks: List[HazardRisk] = []\n",
    "\n",
    "        for fc in inputs_msg.forecasts:\n",
    "            area = fc.get(\"area\", \"Unknown\")\n",
    "            hazard = fc.get(\"hazard\", \"Unknown\")\n",
    "            timeframe = fc.get(\"timeframe\", \"Next 24 hours\")\n",
    "\n",
    "            seed = self._rule_based_seed(fc)\n",
    "            refined = self._refine_with_gemini(fc, seed, inputs_msg.bulletins)\n",
    "\n",
    "            risks.append(\n",
    "                HazardRisk(\n",
    "                    area=area,\n",
    "                    hazard=hazard,\n",
    "                    timeframe=timeframe,\n",
    "                    likelihood=refined[\"likelihood\"],\n",
    "                    impact=refined[\"impact\"],\n",
    "                    rationale=refined[\"rationale\"],\n",
    "                    supporting_evidence=fc.get(\"products\", []),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return HazardRisksMessage(\n",
    "            run_id=inputs_msg.run_id,\n",
    "            as_of=inputs_msg.as_of,\n",
    "            risks=risks,\n",
    "        )\n",
    "\n",
    "\n",
    "# For now, keep Gemini OFF here to avoid quota issues\n",
    "hazard_agent = HazardInterpretationAgent(use_gemini=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a14d9c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:05.854153Z",
     "iopub.status.busy": "2025-11-27T05:20:05.853818Z",
     "iopub.status.idle": "2025-11-27T05:20:05.863709Z",
     "shell.execute_reply": "2025-11-27T05:20:05.862943Z"
    },
    "papermill": {
     "duration": 0.021002,
     "end_time": "2025-11-27T05:20:05.865253",
     "exception": false,
     "start_time": "2025-11-27T05:20:05.844251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 8. Trigger Evaluation Agent (trigger_results A2A message)\n",
    "\n",
    "class TriggerEvaluationAgent:\n",
    "    \"\"\"\n",
    "    Trigger Evaluation Agent\n",
    "\n",
    "    Responsibilities:\n",
    "    - Compare each HazardRisk against the configured TRIGGERS.\n",
    "    - Compute a recommended readiness posture per area.\n",
    "    - Emit a TriggerResultsMessage (A2A: trigger_results) with:\n",
    "        * areas: list of AreaTriggerSummary (name, posture, fired_triggers)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, triggers: List[Dict[str, Any]]):\n",
    "        self.triggers = triggers\n",
    "        # Posture hierarchy for \"upgrade\" logic\n",
    "        self.posture_rank = [\"Normal\", \"Enhanced Monitoring\", \"Response Consideration\"]\n",
    "\n",
    "    def _meets_trigger(self, risk: HazardRisk, trig: Dict[str, Any]) -> bool:\n",
    "        \"\"\"\n",
    "        Return True if a given risk satisfies a trigger's minimum\n",
    "        likelihood and impact thresholds for the matching hazard.\n",
    "        \"\"\"\n",
    "        if risk.hazard != trig[\"hazard\"]:\n",
    "            return False\n",
    "\n",
    "        if LIKELIHOOD_ORDER.index(risk.likelihood) < LIKELIHOOD_ORDER.index(trig[\"min_likelihood\"]):\n",
    "            return False\n",
    "\n",
    "        if IMPACT_ORDER.index(risk.impact) < IMPACT_ORDER.index(trig[\"min_impact\"]):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, risk_msg: HazardRisksMessage) -> TriggerResultsMessage:\n",
    "        \"\"\"\n",
    "        Evaluate a HazardRisksMessage and return a TriggerResultsMessage.\n",
    "\n",
    "        For each area:\n",
    "        - Start with posture = \"Normal\".\n",
    "        - For each risk and trigger that match, upgrade posture if needed.\n",
    "        - Record a list of fired_triggers with rationale.\n",
    "        \"\"\"\n",
    "        # Initialize each area with Normal posture\n",
    "        areas_dict: Dict[str, AreaTriggerSummary] = {}\n",
    "\n",
    "        for r in risk_msg.risks:\n",
    "            if r.area not in areas_dict:\n",
    "                areas_dict[r.area] = AreaTriggerSummary(\n",
    "                    name=r.area,\n",
    "                    posture=\"Normal\",\n",
    "                    fired_triggers=[]\n",
    "                )\n",
    "\n",
    "        # Evaluate triggers for each risk\n",
    "        for r in risk_msg.risks:\n",
    "            for trig in self.triggers:\n",
    "                if self._meets_trigger(r, trig):\n",
    "                    summary = areas_dict[r.area]\n",
    "                    new_posture = trig[\"recommended_posture\"]\n",
    "\n",
    "                    # Upgrade posture if new_posture is \"higher\" in the hierarchy\n",
    "                    if self.posture_rank.index(new_posture) > self.posture_rank.index(summary.posture):\n",
    "                        summary.posture = new_posture\n",
    "\n",
    "                    summary.fired_triggers.append(\n",
    "                        {\n",
    "                            \"trigger_id\": trig[\"id\"],\n",
    "                            \"name\": trig[\"name\"],\n",
    "                            \"rationale\": f\"{r.likelihood} likelihood, {r.impact} impact; {r.rationale}\",\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        return TriggerResultsMessage(\n",
    "            run_id=risk_msg.run_id,\n",
    "            as_of=risk_msg.as_of,\n",
    "            areas=list(areas_dict.values()),\n",
    "        )\n",
    "\n",
    "\n",
    "trigger_agent = TriggerEvaluationAgent(TRIGGERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686ad09e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:05.883002Z",
     "iopub.status.busy": "2025-11-27T05:20:05.882680Z",
     "iopub.status.idle": "2025-11-27T05:20:05.898690Z",
     "shell.execute_reply": "2025-11-27T05:20:05.897866Z"
    },
    "papermill": {
     "duration": 0.027055,
     "end_time": "2025-11-27T05:20:05.900244",
     "exception": false,
     "start_time": "2025-11-27T05:20:05.873189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELL 9 — Briefing Agent (Gemini-generated brief_packet A2A message)\n",
    "\n",
    "class BriefingAgent:\n",
    "    \"\"\"\n",
    "    Briefing Agent\n",
    "\n",
    "    Responsibilities:\n",
    "    - Convert HazardRisksMessage + TriggerResultsMessage into a concise brief\n",
    "      for regional leadership.\n",
    "    - Use Gemini to write the narrative when available.\n",
    "    - Always emit a BriefPacketMessage (A2A: brief_packet) with:\n",
    "        * markdown_brief\n",
    "        * text_brief\n",
    "        * posture_overview (area → posture)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, region_name: str, use_gemini: bool = True):\n",
    "        self.region_name = region_name\n",
    "        self.use_gemini = use_gemini\n",
    "\n",
    "    def _build_structured_summary(\n",
    "        self,\n",
    "        risks_msg: HazardRisksMessage,\n",
    "        triggers_msg: TriggerResultsMessage,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Build a compact JSON-ready summary to feed into Gemini.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"region_name\": self.region_name,\n",
    "            \"as_of\": risks_msg.as_of.isoformat(),\n",
    "            \"risks\": [asdict(r) for r in risks_msg.risks],\n",
    "            \"areas\": [\n",
    "                {\n",
    "                    \"name\": a.name,\n",
    "                    \"posture\": a.posture,\n",
    "                    \"fired_triggers\": a.fired_triggers,\n",
    "                }\n",
    "                for a in triggers_msg.areas\n",
    "            ],\n",
    "        }\n",
    "\n",
    "    def _fallback_brief_text(\n",
    "        self,\n",
    "        risks_msg: HazardRisksMessage,\n",
    "        triggers_msg: TriggerResultsMessage,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Simple non-LLM brief (used if Gemini not configured or errors).\n",
    "        \"\"\"\n",
    "        run_time = risks_msg.as_of\n",
    "        lines: List[str] = []\n",
    "\n",
    "        lines.append(f\"Weather & Hazard Brief for {self.region_name}\")\n",
    "        lines.append(f\"As of {run_time.isoformat()} UTC\\n\")\n",
    "\n",
    "        risks = risks_msg.risks\n",
    "        if not risks:\n",
    "            lines.append(\"Overall: No significant hazards identified for the monitored period.\")\n",
    "        else:\n",
    "            lines.append(\"Key Hazards:\")\n",
    "            for r in risks:\n",
    "                lines.append(\n",
    "                    f\"- {r.area}: {r.hazard} \"\n",
    "                    f\"({r.likelihood} likelihood, {r.impact} impact) – {r.timeframe}. \"\n",
    "                    f\"{r.rationale}\"\n",
    "                )\n",
    "\n",
    "        if triggers_msg.areas:\n",
    "            lines.append(\"\\nRecommended Readiness Posture:\")\n",
    "            for a in triggers_msg.areas:\n",
    "                if not a.fired_triggers:\n",
    "                    lines.append(f\"- {a.name}: {a.posture} (no triggers fired).\")\n",
    "                else:\n",
    "                    reasons = \"; \".join(\n",
    "                        f\"{t['name']} ({t['rationale']})\" for t in a.fired_triggers\n",
    "                    )\n",
    "                    lines.append(\n",
    "                        f\"- {a.name}: {a.posture} due to {reasons}.\"\n",
    "                    )\n",
    "        else:\n",
    "            lines.append(\n",
    "                \"\\nRecommended Readiness Posture: Normal operations for all monitored areas.\"\n",
    "            )\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def generate(\n",
    "        self,\n",
    "        risks_msg: HazardRisksMessage,\n",
    "        triggers_msg: TriggerResultsMessage,\n",
    "    ) -> BriefPacketMessage:\n",
    "        \"\"\"\n",
    "        Main entrypoint used by the orchestrator.\n",
    "        \"\"\"\n",
    "        posture_overview = {a.name: a.posture for a in triggers_msg.areas}\n",
    "\n",
    "        # If no Gemini or use_gemini=False, just use fallback text\n",
    "        if (not self.use_gemini) or (not GEMINI_API_KEY) or (genai is None):\n",
    "            brief_text = self._fallback_brief_text(risks_msg, triggers_msg)\n",
    "        else:\n",
    "            structured = self._build_structured_summary(risks_msg, triggers_msg)\n",
    "            prompt = (\n",
    "                \"You are generating an internal weather & hazard brief for the American Red Cross. \"\n",
    "                \"Write a concise, plain-text brief for regional leadership, with sections:\\n\"\n",
    "                \"1) Overview\\n2) Key Hazards by Area\\n3) Recommended Readiness Posture\\n\\n\"\n",
    "                \"Focus on timing, likelihood, impact, and operational implications. \"\n",
    "                \"Avoid overly technical meteorological jargon. \"\n",
    "                \"Do not use Markdown formatting.\\n\\n\"\n",
    "                \"Input (JSON):\\n\\n\"\n",
    "                f\"{json.dumps(structured)[:4000]}\"\n",
    "            )\n",
    "\n",
    "            brief_text = call_gemini(prompt, max_output_tokens=900)\n",
    "\n",
    "            # If Gemini output looks like an error or raw dump, fall back\n",
    "            if (\n",
    "                not brief_text\n",
    "                or brief_text.startswith(\"[Gemini error\")\n",
    "                or brief_text.startswith(\"[Gemini raw response]\")\n",
    "                or brief_text.startswith(\"[Gemini fallback\")\n",
    "            ):\n",
    "                logging.warning(\"BriefingAgent: falling back to non-LLM brief.\")\n",
    "                brief_text = self._fallback_brief_text(risks_msg, triggers_msg)\n",
    "\n",
    "        markdown_brief = brief_text\n",
    "        text_brief = brief_text\n",
    "\n",
    "        return BriefPacketMessage(\n",
    "            run_id=risks_msg.run_id,\n",
    "            as_of=risks_msg.as_of,\n",
    "            markdown_brief=markdown_brief,\n",
    "            text_brief=text_brief,\n",
    "            posture_overview=posture_overview,\n",
    "        )\n",
    "\n",
    "\n",
    "briefing_agent = BriefingAgent(REGION_NAME, use_gemini=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335e4c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:05.918147Z",
     "iopub.status.busy": "2025-11-27T05:20:05.917832Z",
     "iopub.status.idle": "2025-11-27T05:20:05.928598Z",
     "shell.execute_reply": "2025-11-27T05:20:05.927689Z"
    },
    "papermill": {
     "duration": 0.02176,
     "end_time": "2025-11-27T05:20:05.930156",
     "exception": false,
     "start_time": "2025-11-27T05:20:05.908396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 10. Memory & Logging Agent (including checkpoint state)\n",
    "\n",
    "class MemoryLoggingAgent:\n",
    "    \"\"\"\n",
    "    Memory & Logging Agent\n",
    "\n",
    "    Responsibilities:\n",
    "    - Store run-level info, risks, triggers, and briefs for EDA/evaluation.\n",
    "    - Maintain a CheckpointState for long-running operations (pause/resume).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Per-cycle logs\n",
    "        self.runs: List[Dict[str, Any]] = []        # one row per monitoring cycle\n",
    "        self.risks_log: List[Dict[str, Any]] = []   # one row per HazardRisk\n",
    "        self.triggers_log: List[Dict[str, Any]] = []  # one row per fired trigger\n",
    "        self.briefs_log: List[Dict[str, Any]] = []  # one row per brief\n",
    "\n",
    "        # Checkpoint for long-running ops\n",
    "        self.checkpoint = CheckpointState(\n",
    "            last_run_time=None,\n",
    "            last_posture_by_area={},\n",
    "            last_run_id=None,\n",
    "            operational_period_label=\"Initial\",\n",
    "        )\n",
    "\n",
    "    def log_cycle(\n",
    "        self,\n",
    "        hazard_inputs: HazardInputsMessage,\n",
    "        risks_msg: HazardRisksMessage,\n",
    "        trig_msg: TriggerResultsMessage,\n",
    "        brief_msg: BriefPacketMessage,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Log a full monitoring cycle into in-memory lists and update checkpoint.\n",
    "        \"\"\"\n",
    "        # Run-level log\n",
    "        self.runs.append({\n",
    "            \"run_id\": hazard_inputs.run_id,\n",
    "            \"as_of\": hazard_inputs.as_of,\n",
    "            \"areas\": \",\".join(hazard_inputs.areas),\n",
    "            \"n_forecasts\": len(hazard_inputs.forecasts),\n",
    "            \"n_bulletins\": len(hazard_inputs.bulletins),\n",
    "            \"n_risks\": len(risks_msg.risks),\n",
    "            \"n_trigger_areas\": len(trig_msg.areas),\n",
    "        })\n",
    "\n",
    "        # Risk log\n",
    "        for r in risks_msg.risks:\n",
    "            row = asdict(r)\n",
    "            row[\"run_id\"] = risks_msg.run_id\n",
    "            row[\"as_of\"] = risks_msg.as_of\n",
    "            self.risks_log.append(row)\n",
    "\n",
    "        # Trigger log (only fired ones)\n",
    "        for a in trig_msg.areas:\n",
    "            for t in a.fired_triggers:\n",
    "                self.triggers_log.append({\n",
    "                    \"run_id\": trig_msg.run_id,\n",
    "                    \"as_of\": trig_msg.as_of,\n",
    "                    \"area\": a.name,\n",
    "                    \"posture\": a.posture,\n",
    "                    \"trigger_id\": t[\"trigger_id\"],\n",
    "                    \"trigger_name\": t[\"name\"],\n",
    "                    \"rationale\": t[\"rationale\"],\n",
    "                })\n",
    "\n",
    "        # Brief log\n",
    "        self.briefs_log.append({\n",
    "            \"run_id\": brief_msg.run_id,\n",
    "            \"as_of\": brief_msg.as_of,\n",
    "            \"brief\": brief_msg.text_brief,\n",
    "        })\n",
    "\n",
    "        # Checkpoint update\n",
    "        self.checkpoint = CheckpointState(\n",
    "            last_run_time=hazard_inputs.as_of,\n",
    "            last_posture_by_area=brief_msg.posture_overview,\n",
    "            last_run_id=hazard_inputs.run_id,\n",
    "            operational_period_label=\"Ongoing\",\n",
    "        )\n",
    "\n",
    "    def to_dataframes(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Convert internal logs into pandas DataFrames for analysis and plotting.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"runs\": pd.DataFrame(self.runs),\n",
    "            \"risks\": pd.DataFrame(self.risks_log),\n",
    "            \"triggers\": pd.DataFrame(self.triggers_log),\n",
    "            \"briefs\": pd.DataFrame(self.briefs_log),\n",
    "        }\n",
    "\n",
    "\n",
    "memory_agent = MemoryLoggingAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b7d525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:05.947772Z",
     "iopub.status.busy": "2025-11-27T05:20:05.947487Z",
     "iopub.status.idle": "2025-11-27T05:20:05.956407Z",
     "shell.execute_reply": "2025-11-27T05:20:05.955639Z"
    },
    "papermill": {
     "duration": 0.01981,
     "end_time": "2025-11-27T05:20:05.957950",
     "exception": false,
     "start_time": "2025-11-27T05:20:05.938140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 11. Orchestrator / Scheduler (loop agent, pause/resume)\n",
    "\n",
    "class OrchestratorScheduler:\n",
    "    \"\"\"\n",
    "    Orchestrator / Scheduler\n",
    "\n",
    "    Responsibilities:\n",
    "    - Loop / sequential agent coordinating the full A2A pipeline.\n",
    "    - One \"monitoring cycle\" = Ingestion → Hazard Interpretation →\n",
    "      Trigger Evaluation → Briefing → Memory.\n",
    "    - Supports pause/resume conceptually (for long-running jobs / off-season).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ingestion: DataIngestionAgent,\n",
    "        hazard_int: HazardInterpretationAgent,\n",
    "        trigger_eval: TriggerEvaluationAgent,\n",
    "        briefing: BriefingAgent,\n",
    "        memory: MemoryLoggingAgent,\n",
    "    ):\n",
    "        self.ingestion = ingestion\n",
    "        self.hazard_int = hazard_int\n",
    "        self.trigger_eval = trigger_eval\n",
    "        self.briefing = briefing\n",
    "        self.memory = memory\n",
    "        self.paused = False\n",
    "\n",
    "    def pause(self) -> None:\n",
    "        \"\"\"Pause long-running operations (no new cycles).\"\"\"\n",
    "        self.paused = True\n",
    "\n",
    "    def resume(self) -> None:\n",
    "        \"\"\"\n",
    "        Resume from paused state.\n",
    "\n",
    "        In a Cloud Run deployment, a higher-level wrapper can also reload\n",
    "        checkpoint state from storage before calling run_cycle().\n",
    "        \"\"\"\n",
    "        self.paused = False\n",
    "\n",
    "    def run_cycle(\n",
    "        self,\n",
    "        time_window: str = \"next_72_hours\",\n",
    "        products: Optional[List[str]] = None,\n",
    "        demo_force_hazard: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Run one monitoring cycle over all configured areas.\n",
    "\n",
    "        Flow:\n",
    "          1) Data Ingestion Agent  → hazard_inputs (HazardInputsMessage)\n",
    "          2) Hazard Interpretation → hazard_risks (HazardRisksMessage)\n",
    "          3) Trigger Evaluation    → trigger_results (TriggerResultsMessage)\n",
    "          4) Briefing Agent        → brief_packet (BriefPacketMessage)\n",
    "          5) Memory & Logging      → store logs + update checkpoint\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (hazard_inputs_msg, risks_msg, trig_msg, brief_msg) or None if paused.\n",
    "        \"\"\"\n",
    "        if self.paused:\n",
    "            logging.info(\"Orchestrator is paused; skipping cycle.\")\n",
    "            return None\n",
    "\n",
    "        # 1) Data Ingestion Agent → hazard_inputs\n",
    "        hazard_inputs_msg = self.ingestion.ingest(\n",
    "            time_window=time_window,\n",
    "            products=products,\n",
    "            demo_force_hazard=demo_force_hazard,\n",
    "        )\n",
    "\n",
    "        # 2) Hazard Interpretation Agent → hazard_risks\n",
    "        risks_msg = self.hazard_int.assess(hazard_inputs_msg)\n",
    "\n",
    "        # 3) Trigger Evaluation Agent → trigger_results\n",
    "        trig_msg = self.trigger_eval.evaluate(risks_msg)\n",
    "\n",
    "        # 4) Briefing Agent → brief_packet\n",
    "        brief_msg = self.briefing.generate(risks_msg, trig_msg)\n",
    "\n",
    "        # 5) Memory & Logging Agent\n",
    "        self.memory.log_cycle(hazard_inputs_msg, risks_msg, trig_msg, brief_msg)\n",
    "\n",
    "        return hazard_inputs_msg, risks_msg, trig_msg, brief_msg\n",
    "\n",
    "\n",
    "orchestrator = OrchestratorScheduler(\n",
    "    ingestion=ingestion_agent,\n",
    "    hazard_int=hazard_agent,\n",
    "    trigger_eval=trigger_agent,\n",
    "    briefing=briefing_agent,\n",
    "    memory=memory_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd52774",
   "metadata": {
    "papermill": {
     "duration": 0.007743,
     "end_time": "2025-11-27T05:20:05.973799",
     "exception": false,
     "start_time": "2025-11-27T05:20:05.966056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Demo: Single Monitoring Cycle (Heavy Rain Scenario)\n",
    "\n",
    "In **Cell 12**, we run a single monitoring cycle with:\n",
    "\n",
    "```python\n",
    "result = orchestrator.run_cycle(demo_force_hazard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd5219b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:05.991043Z",
     "iopub.status.busy": "2025-11-27T05:20:05.990689Z",
     "iopub.status.idle": "2025-11-27T05:20:14.358708Z",
     "shell.execute_reply": "2025-11-27T05:20:14.357785Z"
    },
    "papermill": {
     "duration": 8.37878,
     "end_time": "2025-11-27T05:20:14.360381",
     "exception": false,
     "start_time": "2025-11-27T05:20:05.981601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Weather API call OK.\n",
      "INFO:root:Weather API call OK.\n",
      "INFO:root:Weather API call OK.\n",
      "WARNING:root:BriefingAgent: falling back to non-LLM brief.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generated Brief ===\n",
      "Weather & Hazard Brief for American Red Cross | Texas Gulf Coast Region\n",
      "As of 2025-11-27T05:20:05.993705 UTC\n",
      "\n",
      "Key Hazards:\n",
      "- Coastal Bend: Heavy Rain & Flooding (High likelihood, Dangerous impact) – Next 24 hours. QPF=3.20 in/24h.\n",
      "- Houston Metro: No Significant Hazard (Low likelihood, Nuisance impact) – next_72_hours. No significant hazard indicated.\n",
      "- Golden Triangle: No Significant Hazard (Low likelihood, Nuisance impact) – next_72_hours. No significant hazard indicated.\n",
      "\n",
      "Recommended Readiness Posture:\n",
      "- Coastal Bend: Response Consideration due to Heavy Rain – Flash Flood Watch (High likelihood, Dangerous impact; QPF=3.20 in/24h.); Heavy Rain – Possible Flash Flooding (High likelihood, Dangerous impact; QPF=3.20 in/24h.).\n",
      "- Houston Metro: Normal (no triggers fired).\n",
      "- Golden Triangle: Normal (no triggers fired).\n",
      "\n",
      "=== Posture Overview ===\n",
      "- Coastal Bend: Response Consideration\n",
      "- Houston Metro: Normal\n",
      "- Golden Triangle: Normal\n",
      "\n",
      "=== Runs log ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>as_of</th>\n",
       "      <th>areas</th>\n",
       "      <th>n_forecasts</th>\n",
       "      <th>n_bulletins</th>\n",
       "      <th>n_risks</th>\n",
       "      <th>n_trigger_areas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d15ba78f-75cc-4605-be68-23eeb06cc840</td>\n",
       "      <td>2025-11-27 05:20:05.993705</td>\n",
       "      <td>Coastal Bend,Houston Metro,Golden Triangle</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 run_id                      as_of  \\\n",
       "0  d15ba78f-75cc-4605-be68-23eeb06cc840 2025-11-27 05:20:05.993705   \n",
       "\n",
       "                                        areas  n_forecasts  n_bulletins  \\\n",
       "0  Coastal Bend,Houston Metro,Golden Triangle            3            3   \n",
       "\n",
       "   n_risks  n_trigger_areas  \n",
       "0        3                3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Risks log ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>hazard</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>impact</th>\n",
       "      <th>rationale</th>\n",
       "      <th>supporting_evidence</th>\n",
       "      <th>run_id</th>\n",
       "      <th>as_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coastal Bend</td>\n",
       "      <td>Heavy Rain &amp; Flooding</td>\n",
       "      <td>Next 24 hours</td>\n",
       "      <td>High</td>\n",
       "      <td>Dangerous</td>\n",
       "      <td>QPF=3.20 in/24h.</td>\n",
       "      <td>[openweather_current, demo_override]</td>\n",
       "      <td>d15ba78f-75cc-4605-be68-23eeb06cc840</td>\n",
       "      <td>2025-11-27 05:20:05.993705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Houston Metro</td>\n",
       "      <td>No Significant Hazard</td>\n",
       "      <td>next_72_hours</td>\n",
       "      <td>Low</td>\n",
       "      <td>Nuisance</td>\n",
       "      <td>No significant hazard indicated.</td>\n",
       "      <td>[openweather_current]</td>\n",
       "      <td>d15ba78f-75cc-4605-be68-23eeb06cc840</td>\n",
       "      <td>2025-11-27 05:20:05.993705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golden Triangle</td>\n",
       "      <td>No Significant Hazard</td>\n",
       "      <td>next_72_hours</td>\n",
       "      <td>Low</td>\n",
       "      <td>Nuisance</td>\n",
       "      <td>No significant hazard indicated.</td>\n",
       "      <td>[openweather_current]</td>\n",
       "      <td>d15ba78f-75cc-4605-be68-23eeb06cc840</td>\n",
       "      <td>2025-11-27 05:20:05.993705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area                 hazard      timeframe likelihood  \\\n",
       "0     Coastal Bend  Heavy Rain & Flooding  Next 24 hours       High   \n",
       "1    Houston Metro  No Significant Hazard  next_72_hours        Low   \n",
       "2  Golden Triangle  No Significant Hazard  next_72_hours        Low   \n",
       "\n",
       "      impact                         rationale  \\\n",
       "0  Dangerous                  QPF=3.20 in/24h.   \n",
       "1   Nuisance  No significant hazard indicated.   \n",
       "2   Nuisance  No significant hazard indicated.   \n",
       "\n",
       "                    supporting_evidence                                run_id  \\\n",
       "0  [openweather_current, demo_override]  d15ba78f-75cc-4605-be68-23eeb06cc840   \n",
       "1                 [openweather_current]  d15ba78f-75cc-4605-be68-23eeb06cc840   \n",
       "2                 [openweather_current]  d15ba78f-75cc-4605-be68-23eeb06cc840   \n",
       "\n",
       "                       as_of  \n",
       "0 2025-11-27 05:20:05.993705  \n",
       "1 2025-11-27 05:20:05.993705  \n",
       "2 2025-11-27 05:20:05.993705  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Triggers log ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>as_of</th>\n",
       "      <th>area</th>\n",
       "      <th>posture</th>\n",
       "      <th>trigger_id</th>\n",
       "      <th>trigger_name</th>\n",
       "      <th>rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d15ba78f-75cc-4605-be68-23eeb06cc840</td>\n",
       "      <td>2025-11-27 05:20:05.993705</td>\n",
       "      <td>Coastal Bend</td>\n",
       "      <td>Response Consideration</td>\n",
       "      <td>flood_enhanced_monitoring</td>\n",
       "      <td>Heavy Rain – Flash Flood Watch</td>\n",
       "      <td>High likelihood, Dangerous impact; QPF=3.20 in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d15ba78f-75cc-4605-be68-23eeb06cc840</td>\n",
       "      <td>2025-11-27 05:20:05.993705</td>\n",
       "      <td>Coastal Bend</td>\n",
       "      <td>Response Consideration</td>\n",
       "      <td>flood_response_consideration</td>\n",
       "      <td>Heavy Rain – Possible Flash Flooding</td>\n",
       "      <td>High likelihood, Dangerous impact; QPF=3.20 in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 run_id                      as_of  \\\n",
       "0  d15ba78f-75cc-4605-be68-23eeb06cc840 2025-11-27 05:20:05.993705   \n",
       "1  d15ba78f-75cc-4605-be68-23eeb06cc840 2025-11-27 05:20:05.993705   \n",
       "\n",
       "           area                 posture                    trigger_id  \\\n",
       "0  Coastal Bend  Response Consideration     flood_enhanced_monitoring   \n",
       "1  Coastal Bend  Response Consideration  flood_response_consideration   \n",
       "\n",
       "                           trigger_name  \\\n",
       "0        Heavy Rain – Flash Flood Watch   \n",
       "1  Heavy Rain – Possible Flash Flooding   \n",
       "\n",
       "                                           rationale  \n",
       "0  High likelihood, Dangerous impact; QPF=3.20 in...  \n",
       "1  High likelihood, Dangerous impact; QPF=3.20 in...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 12. Single monitoring cycle demo (run in Kaggle to test)\n",
    "\n",
    "# Set demo_force_hazard=True to show a clear heavy rain scenario\n",
    "result = orchestrator.run_cycle(demo_force_hazard=True)\n",
    "\n",
    "if result is None:\n",
    "    print(\"No cycle run (orchestrator paused).\")\n",
    "else:\n",
    "    hazard_inputs_msg, risks_msg, trig_msg, brief_msg = result\n",
    "\n",
    "    print(\"=== Generated Brief ===\")\n",
    "    print(brief_msg.text_brief)\n",
    "    print(\"\\n=== Posture Overview ===\")\n",
    "    for area, posture in brief_msg.posture_overview.items():\n",
    "        print(f\"- {area}: {posture}\")\n",
    "\n",
    "    dfs = memory_agent.to_dataframes()\n",
    "    print(\"\\n=== Runs log ===\")\n",
    "    display(dfs[\"runs\"])\n",
    "    print(\"\\n=== Risks log ===\")\n",
    "    display(dfs[\"risks\"])\n",
    "    print(\"\\n=== Triggers log ===\")\n",
    "    display(dfs[\"triggers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f76029",
   "metadata": {
    "papermill": {
     "duration": 0.008951,
     "end_time": "2025-11-27T05:20:14.378667",
     "exception": false,
     "start_time": "2025-11-27T05:20:14.369716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Multiple Cycles & Long-Running Behavior\n",
    "\n",
    "In a real region workflow, the sentinel wouldn’t run just once.  \n",
    "It would run **every morning / every shift / before a weather event**, so we simulate that here.\n",
    "\n",
    "This cell runs **three back-to-back monitoring cycles**:\n",
    "\n",
    "```python\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Monitoring cycle #{i+1} ---\")\n",
    "    orchestrator.run_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28539eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:14.398032Z",
     "iopub.status.busy": "2025-11-27T05:20:14.397620Z",
     "iopub.status.idle": "2025-11-27T05:20:15.465371Z",
     "shell.execute_reply": "2025-11-27T05:20:15.464339Z"
    },
    "papermill": {
     "duration": 1.07928,
     "end_time": "2025-11-27T05:20:15.466964",
     "exception": false,
     "start_time": "2025-11-27T05:20:14.387684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Monitoring cycle #1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Weather API call OK.\n",
      "INFO:root:Weather API call OK.\n",
      "INFO:root:Weather API call OK.\n",
      "INFO:root:Weather API call OK.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Monitoring cycle #2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Weather API call OK.\n",
      "INFO:root:Weather API call OK.\n",
      "INFO:root:Weather API call OK.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Monitoring cycle #3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Weather API call OK.\n",
      "INFO:root:Weather API call OK.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== All runs so far ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>as_of</th>\n",
       "      <th>areas</th>\n",
       "      <th>n_forecasts</th>\n",
       "      <th>n_bulletins</th>\n",
       "      <th>n_risks</th>\n",
       "      <th>n_trigger_areas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d15ba78f-75cc-4605-be68-23eeb06cc840</td>\n",
       "      <td>2025-11-27 05:20:05.993705</td>\n",
       "      <td>Coastal Bend,Houston Metro,Golden Triangle</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26c49663-a16a-4c1d-9abf-443b4ad30300</td>\n",
       "      <td>2025-11-27 05:20:14.400049</td>\n",
       "      <td>Coastal Bend,Houston Metro,Golden Triangle</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e3eb8c0c-26ff-4859-a614-890168c4e14f</td>\n",
       "      <td>2025-11-27 05:20:14.758070</td>\n",
       "      <td>Coastal Bend,Houston Metro,Golden Triangle</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96e138d9-9743-462e-9201-fa8aea871ee0</td>\n",
       "      <td>2025-11-27 05:20:15.109789</td>\n",
       "      <td>Coastal Bend,Houston Metro,Golden Triangle</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 run_id                      as_of  \\\n",
       "0  d15ba78f-75cc-4605-be68-23eeb06cc840 2025-11-27 05:20:05.993705   \n",
       "1  26c49663-a16a-4c1d-9abf-443b4ad30300 2025-11-27 05:20:14.400049   \n",
       "2  e3eb8c0c-26ff-4859-a614-890168c4e14f 2025-11-27 05:20:14.758070   \n",
       "3  96e138d9-9743-462e-9201-fa8aea871ee0 2025-11-27 05:20:15.109789   \n",
       "\n",
       "                                        areas  n_forecasts  n_bulletins  \\\n",
       "0  Coastal Bend,Houston Metro,Golden Triangle            3            3   \n",
       "1  Coastal Bend,Houston Metro,Golden Triangle            3            3   \n",
       "2  Coastal Bend,Houston Metro,Golden Triangle            3            3   \n",
       "3  Coastal Bend,Houston Metro,Golden Triangle            3            3   \n",
       "\n",
       "   n_risks  n_trigger_areas  \n",
       "0        3                3  \n",
       "1        3                3  \n",
       "2        3                3  \n",
       "3        3                3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Checkpoint state ===\n",
      "CheckpointState(last_run_time=datetime.datetime(2025, 11, 27, 5, 20, 15, 109789), last_posture_by_area={'Coastal Bend': 'Normal', 'Houston Metro': 'Normal', 'Golden Triangle': 'Normal'}, last_run_id='96e138d9-9743-462e-9201-fa8aea871ee0', operational_period_label='Ongoing')\n"
     ]
    }
   ],
   "source": [
    "briefing_agent.use_gemini = False\n",
    "\n",
    "# 13. Multiple cycles simulation (conceptual long-running behavior)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Monitoring cycle #{i+1} ---\")\n",
    "    orchestrator.run_cycle()\n",
    "\n",
    "dfs_multi = memory_agent.to_dataframes()\n",
    "print(\"\\n=== All runs so far ===\")\n",
    "display(dfs_multi[\"runs\"])\n",
    "\n",
    "print(\"\\n=== Checkpoint state ===\")\n",
    "print(memory_agent.checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512cc758",
   "metadata": {
    "papermill": {
     "duration": 0.009877,
     "end_time": "2025-11-27T05:20:15.486925",
     "exception": false,
     "start_time": "2025-11-27T05:20:15.477048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Checkpointing to Cloud Storage (GCS)\n",
    "\n",
    "To run this system as a **cloud service**, we need a way to:\n",
    "\n",
    "- Remember the **last run** across container restarts.  \n",
    "- Persist the last known **posture by area** and `run_id`.  \n",
    "\n",
    "This section adds two helpers that talk to **Google Cloud Storage (GCS)**:\n",
    "\n",
    "- `save_checkpoint_to_gcs(checkpoint: CheckpointState)`\n",
    "- `load_checkpoint_from_gcs() -> Optional[CheckpointState]`\n",
    "\n",
    "### How It Works\n",
    "\n",
    "- `CHECKPOINT_BLOB_NAME = \"weather_hazard_sentinel/checkpoint.json\"`  \n",
    "  → This is the path inside the GCS bucket where the checkpoint JSON is stored.\n",
    "\n",
    "- `save_checkpoint_to_gcs(...)`:\n",
    "  - Serializes:\n",
    "    - `last_run_time` (ISO format)\n",
    "    - `last_posture_by_area`\n",
    "    - `last_run_id`\n",
    "    - `operational_period_label`\n",
    "  - Uploads the JSON to `gs://<GCS_BUCKET>/weather_hazard_sentinel/checkpoint.json`.\n",
    "\n",
    "- `load_checkpoint_from_gcs()`:\n",
    "  - Checks whether the blob exists.  \n",
    "  - If it does, downloads + parses JSON back into a `CheckpointState`.  \n",
    "  - If not, returns `None`.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "To actually use this in production, you need:\n",
    "\n",
    "- `google-cloud-storage` installed in the environment.  \n",
    "- A valid `GCP_PROJECT_ID`.  \n",
    "- A `GCS_BUCKET` with correct permissions for the service account (Cloud Run / Cloud Functions).  \n",
    "\n",
    "In Kaggle, these functions are defined and **safe to call**, but the notebook logs:\n",
    "\n",
    "> “GCS storage not configured; skipping checkpoint load/save.”\n",
    "\n",
    "which is expected because there is no GCP auth in this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2684601f",
   "metadata": {
    "papermill": {
     "duration": 0.009846,
     "end_time": "2025-11-27T05:20:15.506579",
     "exception": false,
     "start_time": "2025-11-27T05:20:15.496733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Deployment Flow — Cloud Run + Cloud Scheduler\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[\"Developer Notebook / GitHub Repo\"]\n",
    "    B[\"Container Build & Push\"]\n",
    "    C[\"Cloud Run Service\\nweather-hazard-sentinel\"]\n",
    "    D[\"Orchestrator Cycle\\nrun_cycle()\"]\n",
    "    E[\"GCS Checkpoint\\ncheckpoint.json\"]\n",
    "\n",
    "    A --> B --> C\n",
    "    C -->|\"POST /run\"| D\n",
    "    D --> E\n",
    "\n",
    "    subgraph Scheduler\n",
    "        F[\"Cloud Scheduler\\nCron Job (HTTP)\"]\n",
    "    end\n",
    "\n",
    "    F -->|\"Trigger /run\"| C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07a142be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:15.529426Z",
     "iopub.status.busy": "2025-11-27T05:20:15.529139Z",
     "iopub.status.idle": "2025-11-27T05:20:30.096501Z",
     "shell.execute_reply": "2025-11-27T05:20:30.095581Z"
    },
    "papermill": {
     "duration": 14.580566,
     "end_time": "2025-11-27T05:20:30.098321",
     "exception": false,
     "start_time": "2025-11-27T05:20:15.517755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 14. GCS checkpoint save/load helpers (for Cloud Run / cron deployment)\n",
    "\n",
    "# NOTE:\n",
    "# - This requires `google-cloud-storage` to be installed and proper service account auth.\n",
    "#   In Kaggle, you can install the library, but auth needs a key or Workload Identity in Cloud Run.\n",
    "# - You won't usually run this in Kaggle; it's for the Cloud Run service.\n",
    "\n",
    "try:\n",
    "    from google.cloud import storage\n",
    "except Exception as e:\n",
    "    storage = None\n",
    "    logging.warning(f\"google-cloud-storage not available: {e}\")\n",
    "\n",
    "CHECKPOINT_BLOB_NAME = \"weather_hazard_sentinel/checkpoint.json\"\n",
    "\n",
    "def save_checkpoint_to_gcs(checkpoint: CheckpointState):\n",
    "    if not storage or not GCS_BUCKET:\n",
    "        logging.warning(\"GCS storage not configured; skipping checkpoint save.\")\n",
    "        return\n",
    "\n",
    "    client = storage.Client(project=GCP_PROJECT_ID or None)\n",
    "    bucket = client.bucket(GCS_BUCKET)\n",
    "    blob = bucket.blob(CHECKPOINT_BLOB_NAME)\n",
    "\n",
    "    payload = {\n",
    "        \"last_run_time\": checkpoint.last_run_time.isoformat() if checkpoint.last_run_time else None,\n",
    "        \"last_posture_by_area\": checkpoint.last_posture_by_area,\n",
    "        \"last_run_id\": checkpoint.last_run_id,\n",
    "        \"operational_period_label\": checkpoint.operational_period_label,\n",
    "    }\n",
    "\n",
    "    blob.upload_from_string(json.dumps(payload), content_type=\"application/json\")\n",
    "    logging.info(f\"Checkpoint saved to gs://{GCS_BUCKET}/{CHECKPOINT_BLOB_NAME}\")\n",
    "\n",
    "\n",
    "def load_checkpoint_from_gcs() -> Optional[CheckpointState]:\n",
    "    if not storage or not GCS_BUCKET:\n",
    "        logging.warning(\"GCS storage not configured; skipping checkpoint load.\")\n",
    "        return None\n",
    "\n",
    "    client = storage.Client(project=GCP_PROJECT_ID or None)\n",
    "    bucket = client.bucket(GCS_BUCKET)\n",
    "    blob = bucket.blob(CHECKPOINT_BLOB_NAME)\n",
    "\n",
    "    if not blob.exists():\n",
    "        logging.info(\"No checkpoint found in GCS; returning None.\")\n",
    "        return None\n",
    "\n",
    "    data = json.loads(blob.download_as_text())\n",
    "    last_run_time = dt.datetime.fromisoformat(data[\"last_run_time\"]) if data[\"last_run_time\"] else None\n",
    "\n",
    "    cp = CheckpointState(\n",
    "        last_run_time=last_run_time,\n",
    "        last_posture_by_area=data.get(\"last_posture_by_area\", {}),\n",
    "        last_run_id=data.get(\"last_run_id\"),\n",
    "        operational_period_label=data.get(\"operational_period_label\", \"Ongoing\"),\n",
    "    )\n",
    "\n",
    "    logging.info(f\"Checkpoint loaded from gs://{GCS_BUCKET}/{CHECKPOINT_BLOB_NAME}\")\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb13dfb",
   "metadata": {
    "papermill": {
     "duration": 0.009756,
     "end_time": "2025-11-27T05:20:30.118268",
     "exception": false,
     "start_time": "2025-11-27T05:20:30.108512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Cloud Run Integration (Cron-Driven Agent)\n",
    "\n",
    "In production, we want the sentinel to run on a **schedule** without opening the notebook.\n",
    "\n",
    "A simple pattern is:\n",
    "\n",
    "- Deploy the core logic to **Cloud Run** (or Cloud Functions).  \n",
    "- Trigger it with **Cloud Scheduler** (e.g., every day at 07:30, or every 3 hours).  \n",
    "\n",
    "This cell defines `orchestrator_cloud_run_cycle()` as the **core function** a web handler would call.\n",
    "\n",
    "### Flow in `orchestrator_cloud_run_cycle()`\n",
    "\n",
    "1. **Load checkpoint** from GCS (if present):\n",
    "\n",
    "   ```python\n",
    "   cp = load_checkpoint_from_gcs()\n",
    "   if cp:\n",
    "       memory_agent.checkpoint = cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1c4b491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:30.139690Z",
     "iopub.status.busy": "2025-11-27T05:20:30.139212Z",
     "iopub.status.idle": "2025-11-27T05:20:30.145630Z",
     "shell.execute_reply": "2025-11-27T05:20:30.144694Z"
    },
    "papermill": {
     "duration": 0.019101,
     "end_time": "2025-11-27T05:20:30.147078",
     "exception": false,
     "start_time": "2025-11-27T05:20:30.127977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 15. Example wiring for Cloud Run main handler (conceptual)\n",
    "\n",
    "\"\"\"\n",
    "This cell provides a function you can reuse in a Cloud Run service.\n",
    "\n",
    "- Use `orchestrator_cloud_run_cycle` as the core logic.\n",
    "- Wrap it in a Flask/FastAPI/Functions handler to be triggered by Cloud Scheduler.\n",
    "\"\"\"\n",
    "\n",
    "def orchestrator_cloud_run_cycle():\n",
    "    \"\"\"\n",
    "    Core monitoring cycle for Cloud Run / cron job.\n",
    "    - Load checkpoint from GCS\n",
    "    - Run one cycle\n",
    "    - Save updated checkpoint\n",
    "    \"\"\"\n",
    "    cp = load_checkpoint_from_gcs()\n",
    "    if cp:\n",
    "        # In a more advanced version, you might adjust behavior based on cp.\n",
    "        memory_agent.checkpoint = cp\n",
    "\n",
    "    result = orchestrator.run_cycle()\n",
    "\n",
    "    if result is None:\n",
    "        logging.info(\"No cycle run (orchestrator paused in cloud context).\")\n",
    "        return\n",
    "\n",
    "    # After a successful cycle, save checkpoint\n",
    "    save_checkpoint_to_gcs(memory_agent.checkpoint)\n",
    "    logging.info(\"Cloud Run cycle completed.\")\n",
    "\n",
    "    return \"OK\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4102255",
   "metadata": {
    "papermill": {
     "duration": 0.01035,
     "end_time": "2025-11-27T05:20:30.167668",
     "exception": false,
     "start_time": "2025-11-27T05:20:30.157318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. Local Sanity Check for Cloud Run Cycle\n",
    "\n",
    "We also include a quick **local test**:\n",
    "\n",
    "```python\n",
    "try:\n",
    "    resp = orchestrator_cloud_run_cycle()\n",
    "    print(\"orchestrator_cloud_run_cycle response:\", resp)\n",
    "except Exception as e:\n",
    "    print(\"Error in orchestrator_cloud_run_cycle (expected if no GCS auth):\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56ec4ee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:30.189143Z",
     "iopub.status.busy": "2025-11-27T05:20:30.188403Z",
     "iopub.status.idle": "2025-11-27T05:20:30.557283Z",
     "shell.execute_reply": "2025-11-27T05:20:30.556223Z"
    },
    "papermill": {
     "duration": 0.381554,
     "end_time": "2025-11-27T05:20:30.558940",
     "exception": false,
     "start_time": "2025-11-27T05:20:30.177386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:GCS storage not configured; skipping checkpoint load.\n",
      "INFO:root:Weather API call OK.\n",
      "INFO:root:Weather API call OK.\n",
      "INFO:root:Weather API call OK.\n",
      "WARNING:root:GCS storage not configured; skipping checkpoint save.\n",
      "INFO:root:Cloud Run cycle completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orchestrator_cloud_run_cycle response: OK\n"
     ]
    }
   ],
   "source": [
    "# 16. Placeholder: simple local test for Cloud Run cycle function\n",
    "\n",
    "# You won't call this in Cloud Run; but you can run once in Kaggle just to ensure\n",
    "# the function definition doesn't crash (GCS may still be unconfigured here).\n",
    "try:\n",
    "    resp = orchestrator_cloud_run_cycle()\n",
    "    print(\"orchestrator_cloud_run_cycle response:\", resp)\n",
    "except Exception as e:\n",
    "    print(\"Error in orchestrator_cloud_run_cycle (expected if no GCS auth):\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32758f30",
   "metadata": {
    "papermill": {
     "duration": 0.013016,
     "end_time": "2025-11-27T05:20:30.583609",
     "exception": false,
     "start_time": "2025-11-27T05:20:30.570593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deployment Artifacts (Cloud Run / FastAPI)\n",
    "\n",
    "This section shows how the notebook logic can be deployed as a\n",
    "Cloud Run service triggered by Cloud Scheduler.\n",
    "\n",
    "Files:\n",
    "\n",
    "- `agents.py` — core orchestrator + agents, refactored for deployment.\n",
    "- `main.py` — FastAPI wrapper exposing a `/run` endpoint.\n",
    "- `Dockerfile` — container image for Cloud Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4502469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:30.611181Z",
     "iopub.status.busy": "2025-11-27T05:20:30.610828Z",
     "iopub.status.idle": "2025-11-27T05:20:30.635876Z",
     "shell.execute_reply": "2025-11-27T05:20:30.634667Z"
    },
    "papermill": {
     "duration": 0.040931,
     "end_time": "2025-11-27T05:20:30.638202",
     "exception": false,
     "start_time": "2025-11-27T05:20:30.597271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing agents.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile agents.py\n",
    "\n",
    "# Exported from notebook:\n",
    "# Copy all code from Cells 1–15 here manually for Cloud Run.\n",
    "# (Notebook users see this as reference; GitHub repo will contain full file.)\n",
    "\n",
    "# ===== agents.py (deployment module) =====\n",
    "\"\"\"\n",
    "Core Weather & Hazard Sentinel logic for deployment.\n",
    "\n",
    "This file is a refactored version of the Kaggle notebook code:\n",
    "- Uses os.getenv(...) instead of kaggle_secrets.\n",
    "- Omits visualization / display calls.\n",
    "- Exposes `orchestrator_cloud_run_cycle()` for Cloud Run / FastAPI.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import datetime as dt\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Optional: GCS storage for checkpoint\n",
    "try:\n",
    "    from google.cloud import storage\n",
    "except Exception:\n",
    "    storage = None\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# CONFIG (env-driven for deployment)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "REGION_NAME = os.getenv(\"REGION_NAME\", \"American Red Cross | Texas Gulf Coast Region\")\n",
    "\n",
    "REGION_AREAS = [\n",
    "    \"Coastal Bend\",\n",
    "    \"Houston Metro\",\n",
    "    \"Golden Triangle\",\n",
    "]\n",
    "\n",
    "REGION_AREA_COORDS = {\n",
    "    \"Coastal Bend\": {\"lat\": 27.8, \"lon\": -97.4},\n",
    "    \"Houston Metro\": {\"lat\": 29.76, \"lon\": -95.37},\n",
    "    \"Golden Triangle\": {\"lat\": 30.08, \"lon\": -94.13},\n",
    "}\n",
    "\n",
    "HAZARD_TYPES = [\n",
    "    \"Heavy Rain & Flooding\",\n",
    "    \"Severe Storms\",\n",
    "    \"Excessive Heat\",\n",
    "    \"Wildfire\",\n",
    "]\n",
    "\n",
    "TRIGGERS = [\n",
    "    {\n",
    "        \"id\": \"flood_enhanced_monitoring\",\n",
    "        \"hazard\": \"Heavy Rain & Flooding\",\n",
    "        \"min_likelihood\": \"Medium\",\n",
    "        \"min_impact\": \"Disruptive\",\n",
    "        \"recommended_posture\": \"Enhanced Monitoring\",\n",
    "        \"name\": \"Heavy Rain – Flash Flood Watch\",\n",
    "        \"note\": \"Consider readiness actions for flood-prone areas.\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"flood_response_consideration\",\n",
    "        \"hazard\": \"Heavy Rain & Flooding\",\n",
    "        \"min_likelihood\": \"High\",\n",
    "        \"min_impact\": \"Dangerous\",\n",
    "        \"recommended_posture\": \"Response Consideration\",\n",
    "        \"name\": \"Heavy Rain – Possible Flash Flooding\",\n",
    "        \"note\": \"Discuss shelter readiness and resource pre-positioning.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "LIKELIHOOD_ORDER = [\"Low\", \"Medium\", \"High\"]\n",
    "IMPACT_ORDER = [\"Nuisance\", \"Disruptive\", \"Dangerous\"]\n",
    "\n",
    "WEATHER_API_KEY = os.getenv(\"WEATHER_API_KEY\", \"\")\n",
    "WEATHER_API_URL = os.getenv(\"WEATHER_API_URL\", \"https://api.openweathermap.org/data/2.5/weather\")\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "GEMINI_MODEL = os.getenv(\"GEMINI_MODEL\", \"gemini-2.5-pro\")\n",
    "\n",
    "GCP_PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\", \"\")\n",
    "GCS_BUCKET = os.getenv(\"GCS_BUCKET\", \"\")\n",
    "CHECKPOINT_BLOB_NAME = \"weather_hazard_sentinel/checkpoint.json\"\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Gemini client (optional)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    if GEMINI_API_KEY:\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        logging.info(\"Gemini client configured in agents.py.\")\n",
    "    else:\n",
    "        genai = None\n",
    "        logging.info(\"GEMINI_API_KEY not set; Gemini disabled in agents.py.\")\n",
    "except Exception as e:\n",
    "    genai = None\n",
    "    logging.warning(f\"Could not import google.generativeai in agents.py: {e}\")\n",
    "\n",
    "\n",
    "def call_gemini(prompt: str,\n",
    "                model_name: str = GEMINI_MODEL,\n",
    "                temperature: float = 0.2,\n",
    "                max_output_tokens: int = 512) -> str:\n",
    "    if not genai or not GEMINI_API_KEY:\n",
    "        return \"[Gemini disabled] \" + prompt[:200]\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                temperature=temperature,\n",
    "                max_output_tokens=max_output_tokens,\n",
    "            ),\n",
    "        )\n",
    "        try:\n",
    "            if getattr(response, \"candidates\", None):\n",
    "                parts = response.candidates[0].content.parts\n",
    "                text = \"\".join(getattr(p, \"text\", \"\") for p in parts)\n",
    "                if text.strip():\n",
    "                    return text\n",
    "        except Exception as inner:\n",
    "            logging.warning(f\"Could not extract Gemini text: {inner}\")\n",
    "        return \"[Gemini raw response] \" + str(response)[:400]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Gemini call failed: {e}\")\n",
    "        return f\"[Gemini error: {e}]\"\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Dataclasses (A2A schemas)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class HazardInputsMessage:\n",
    "    run_id: str\n",
    "    as_of: dt.datetime\n",
    "    areas: List[str]\n",
    "    forecasts: List[Dict[str, Any]]\n",
    "    bulletins: List[str]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HazardRisk:\n",
    "    area: str\n",
    "    hazard: str\n",
    "    timeframe: str\n",
    "    likelihood: str\n",
    "    impact: str\n",
    "    rationale: str\n",
    "    supporting_evidence: List[str]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HazardRisksMessage:\n",
    "    run_id: str\n",
    "    as_of: dt.datetime\n",
    "    risks: List[HazardRisk]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AreaTriggerSummary:\n",
    "    name: str\n",
    "    posture: str\n",
    "    fired_triggers: List[Dict[str, Any]]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TriggerResultsMessage:\n",
    "    run_id: str\n",
    "    as_of: dt.datetime\n",
    "    areas: List[AreaTriggerSummary]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BriefPacketMessage:\n",
    "    run_id: str\n",
    "    as_of: dt.datetime\n",
    "    markdown_brief: str\n",
    "    text_brief: str\n",
    "    posture_overview: Dict[str, str]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CheckpointState:\n",
    "    last_run_time: Optional[dt.datetime]\n",
    "    last_posture_by_area: Dict[str, str]\n",
    "    last_run_id: Optional[str]\n",
    "    operational_period_label: str\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Weather helper\n",
    "# -------------------------------------------------------\n",
    "\n",
    "def fetch_weather_raw(lat: float,\n",
    "                      lon: float,\n",
    "                      units: str = \"metric\") -> Dict[str, Any]:\n",
    "    if not WEATHER_API_KEY:\n",
    "        logging.warning(\"No WEATHER_API_KEY set; returning empty weather.\")\n",
    "        return {}\n",
    "\n",
    "    params = {\"lat\": lat, \"lon\": lon, \"units\": units, \"appid\": WEATHER_API_KEY}\n",
    "    try:\n",
    "        resp = requests.get(WEATHER_API_URL, params=params, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Weather API call failed: {e}\")\n",
    "        return {}\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Agents: Ingestion, Hazard Interpretation, Trigger Evaluation, Briefing, Memory\n",
    "# (same logic as notebook, but without Kaggle-specific bits)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "class DataIngestionAgent:\n",
    "    def __init__(self, region_areas: List[str]):\n",
    "        self.region_areas = region_areas\n",
    "\n",
    "    def ingest(self,\n",
    "               time_window: str = \"next_24_hours\",\n",
    "               products: Optional[List[str]] = None,\n",
    "               demo_force_hazard: bool = False) -> HazardInputsMessage:\n",
    "        if products is None:\n",
    "            products = [\"openweather_current\"]\n",
    "\n",
    "        run_id = str(uuid.uuid4())\n",
    "        now = dt.datetime.utcnow()\n",
    "        forecasts: List[Dict[str, Any]] = []\n",
    "        bulletins: List[str] = []\n",
    "\n",
    "        for area in self.region_areas:\n",
    "            coords = REGION_AREA_COORDS.get(area)\n",
    "            if not coords:\n",
    "                continue\n",
    "            raw = fetch_weather_raw(coords[\"lat\"], coords[\"lon\"])\n",
    "            if not raw:\n",
    "                forecasts.append({\n",
    "                    \"area\": area,\n",
    "                    \"hazard\": \"Unknown\",\n",
    "                    \"timeframe\": time_window,\n",
    "                    \"products\": products,\n",
    "                })\n",
    "                bulletins.append(f\"{area}: Unable to retrieve external weather data.\")\n",
    "                continue\n",
    "\n",
    "            main = raw.get(\"main\", {})\n",
    "            temp = float(main.get(\"temp\", 0.0))\n",
    "            feels_like = float(main.get(\"feels_like\", temp))\n",
    "            rain_mm = 0.0\n",
    "            if \"rain\" in raw:\n",
    "                rain = raw[\"rain\"]\n",
    "                rain_mm = float(rain.get(\"1h\", rain.get(\"3h\", 0.0)))\n",
    "            qpf_inches_24h = rain_mm / 25.4 if rain_mm else 0.0\n",
    "\n",
    "            hazards_here = []\n",
    "            if qpf_inches_24h >= 0.1:\n",
    "                hazards_here.append({\n",
    "                    \"area\": area,\n",
    "                    \"hazard\": \"Heavy Rain & Flooding\",\n",
    "                    \"qpf_inches_24h\": qpf_inches_24h,\n",
    "                    \"timeframe\": \"Next 6–24 hours\",\n",
    "                    \"products\": products,\n",
    "                })\n",
    "\n",
    "            if feels_like >= 35.0:\n",
    "                hi = feels_like * 1.1\n",
    "                hazards_here.append({\n",
    "                    \"area\": area,\n",
    "                    \"hazard\": \"Excessive Heat\",\n",
    "                    \"heat_index\": hi,\n",
    "                    \"timeframe\": \"Afternoon\",\n",
    "                    \"products\": products,\n",
    "                })\n",
    "\n",
    "            if not hazards_here:\n",
    "                hazards_here.append({\n",
    "                    \"area\": area,\n",
    "                    \"hazard\": \"No Significant Hazard\",\n",
    "                    \"timeframe\": time_window,\n",
    "                    \"products\": products,\n",
    "                })\n",
    "\n",
    "            if demo_force_hazard and area == \"Coastal Bend\":\n",
    "                hazards_here = [{\n",
    "                    \"area\": area,\n",
    "                    \"hazard\": \"Heavy Rain & Flooding\",\n",
    "                    \"qpf_inches_24h\": 3.2,\n",
    "                    \"timeframe\": \"Next 24 hours\",\n",
    "                    \"products\": products + [\"demo_override\"],\n",
    "                }]\n",
    "\n",
    "            forecasts.extend(hazards_here)\n",
    "\n",
    "            summary_text = (\n",
    "                f\"Current temp {temp:.1f}°C (feels like {feels_like:.1f}°C), \"\n",
    "                f\"rain last hour {rain_mm:.1f} mm. \"\n",
    "            )\n",
    "            if hazards_here and hazards_here[0][\"hazard\"] != \"No Significant Hazard\":\n",
    "                summary_text += \"Potential operational impacts due to highlighted hazards.\"\n",
    "            else:\n",
    "                summary_text += \"No significant hazards detected at this time.\"\n",
    "            bulletins.append(f\"{area}: {summary_text}\")\n",
    "\n",
    "        return HazardInputsMessage(\n",
    "            run_id=run_id,\n",
    "            as_of=now,\n",
    "            areas=self.region_areas,\n",
    "            forecasts=forecasts,\n",
    "            bulletins=bulletins,\n",
    "        )\n",
    "\n",
    "class HazardInterpretationAgent:\n",
    "    def __init__(self, use_gemini: bool = False):\n",
    "        self.use_gemini = use_gemini\n",
    "\n",
    "    def _rule_based_seed(self, fc: Dict[str, Any]) -> Dict[str, str]:\n",
    "        hazard = fc.get(\"hazard\", \"Unknown\")\n",
    "        if hazard == \"Heavy Rain & Flooding\":\n",
    "            qpf = float(fc.get(\"qpf_inches_24h\", 0.0))\n",
    "            if qpf >= 3.0:\n",
    "                return {\"likelihood\": \"High\", \"impact\": \"Dangerous\", \"rationale\": f\"QPF={qpf:.2f} in/24h.\"}\n",
    "            elif qpf >= 1.5:\n",
    "                return {\"likelihood\": \"Medium\", \"impact\": \"Disruptive\", \"rationale\": f\"QPF={qpf:.2f} in/24h.\"}\n",
    "            elif qpf >= 0.5:\n",
    "                return {\"likelihood\": \"Low\", \"impact\": \"Nuisance\", \"rationale\": f\"QPF={qpf:.2f} in/24h.\"}\n",
    "            else:\n",
    "                return {\"likelihood\": \"Low\", \"impact\": \"Nuisance\", \"rationale\": \"Minimal QPF.\"}\n",
    "        if hazard == \"Excessive Heat\":\n",
    "            hi = float(fc.get(\"heat_index\", 0.0))\n",
    "            if hi >= 108:\n",
    "                return {\"likelihood\": \"High\", \"impact\": \"Dangerous\", \"rationale\": f\"Heat index={hi:.1f}.\"}\n",
    "            elif hi >= 103:\n",
    "                return {\"likelihood\": \"Medium\", \"impact\": \"Disruptive\", \"rationale\": f\"Heat index={hi:.1f}.\"}\n",
    "            elif hi >= 95:\n",
    "                return {\"likelihood\": \"Low\", \"impact\": \"Nuisance\", \"rationale\": f\"Heat index={hi:.1f}.\"}\n",
    "            else:\n",
    "                return {\"likelihood\": \"Low\", \"impact\": \"Nuisance\", \"rationale\": \"Heat not critical.\"}\n",
    "        if hazard == \"No Significant Hazard\":\n",
    "            return {\"likelihood\": \"Low\", \"impact\": \"Nuisance\", \"rationale\": \"No significant hazard indicated.\"}\n",
    "        return {\"likelihood\": \"Low\", \"impact\": \"Nuisance\", \"rationale\": \"Default / unknown hazard.\"}\n",
    "\n",
    "    def assess(self, inputs_msg: HazardInputsMessage) -> HazardRisksMessage:\n",
    "        risks: List[HazardRisk] = []\n",
    "        for fc in inputs_msg.forecasts:\n",
    "            area = fc.get(\"area\", \"Unknown\")\n",
    "            hazard = fc.get(\"hazard\", \"Unknown\")\n",
    "            timeframe = fc.get(\"timeframe\", \"Next 24 hours\")\n",
    "            seed = self._rule_based_seed(fc)\n",
    "            risks.append(\n",
    "                HazardRisk(\n",
    "                    area=area,\n",
    "                    hazard=hazard,\n",
    "                    timeframe=timeframe,\n",
    "                    likelihood=seed[\"likelihood\"],\n",
    "                    impact=seed[\"impact\"],\n",
    "                    rationale=seed[\"rationale\"],\n",
    "                    supporting_evidence=fc.get(\"products\", []),\n",
    "                )\n",
    "            )\n",
    "        return HazardRisksMessage(\n",
    "            run_id=inputs_msg.run_id,\n",
    "            as_of=inputs_msg.as_of,\n",
    "            risks=risks,\n",
    "        )\n",
    "\n",
    "class TriggerEvaluationAgent:\n",
    "    def __init__(self, triggers: List[Dict[str, Any]]):\n",
    "        self.triggers = triggers\n",
    "        self.posture_rank = [\"Normal\", \"Enhanced Monitoring\", \"Response Consideration\"]\n",
    "\n",
    "    def _meets_trigger(self, risk: HazardRisk, trig: Dict[str, Any]) -> bool:\n",
    "        if risk.hazard != trig[\"hazard\"]:\n",
    "            return False\n",
    "        if LIKELIHOOD_ORDER.index(risk.likelihood) < LIKELIHOOD_ORDER.index(trig[\"min_likelihood\"]):\n",
    "            return False\n",
    "        if IMPACT_ORDER.index(risk.impact) < IMPACT_ORDER.index(trig[\"min_impact\"]):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, risk_msg: HazardRisksMessage) -> TriggerResultsMessage:\n",
    "        areas_dict: Dict[str, AreaTriggerSummary] = {}\n",
    "        for r in risk_msg.risks:\n",
    "            if r.area not in areas_dict:\n",
    "                areas_dict[r.area] = AreaTriggerSummary(name=r.area, posture=\"Normal\", fired_triggers=[])\n",
    "        for r in risk_msg.risks:\n",
    "            for trig in self.triggers:\n",
    "                if self._meets_trigger(r, trig):\n",
    "                    summary = areas_dict[r.area]\n",
    "                    new_posture = trig[\"recommended_posture\"]\n",
    "                    if self.posture_rank.index(new_posture) > self.posture_rank.index(summary.posture):\n",
    "                        summary.posture = new_posture\n",
    "                    summary.fired_triggers.append(\n",
    "                        {\n",
    "                            \"trigger_id\": trig[\"id\"],\n",
    "                            \"name\": trig[\"name\"],\n",
    "                            \"rationale\": f\"{r.likelihood} likelihood, {r.impact} impact; {r.rationale}\",\n",
    "                        }\n",
    "                    )\n",
    "        return TriggerResultsMessage(\n",
    "            run_id=risk_msg.run_id,\n",
    "            as_of=risk_msg.as_of,\n",
    "            areas=list(areas_dict.values()),\n",
    "        )\n",
    "\n",
    "class BriefingAgent:\n",
    "    def __init__(self, region_name: str, use_gemini: bool = True):\n",
    "        self.region_name = region_name\n",
    "        self.use_gemini = use_gemini\n",
    "\n",
    "    def _fallback_brief_text(self, risks_msg: HazardRisksMessage, triggers_msg: TriggerResultsMessage) -> str:\n",
    "        run_time = risks_msg.as_of\n",
    "        lines: List[str] = []\n",
    "        lines.append(f\"Weather & Hazard Brief for {self.region_name}\")\n",
    "        lines.append(f\"As of {run_time.isoformat()} UTC\\n\")\n",
    "        risks = risks_msg.risks\n",
    "        if not risks:\n",
    "            lines.append(\"Overall: No significant hazards identified for the monitored period.\")\n",
    "        else:\n",
    "            lines.append(\"Key Hazards:\")\n",
    "            for r in risks:\n",
    "                lines.append(\n",
    "                    f\"- {r.area}: {r.hazard} \"\n",
    "                    f\"({r.likelihood} likelihood, {r.impact} impact) – {r.timeframe}. \"\n",
    "                    f\"{r.rationale}\"\n",
    "                )\n",
    "        if triggers_msg.areas:\n",
    "            lines.append(\"\\nRecommended Readiness Posture:\")\n",
    "            for a in triggers_msg.areas:\n",
    "                if not a.fired_triggers:\n",
    "                    lines.append(f\"- {a.name}: {a.posture} (no triggers fired).\")\n",
    "                else:\n",
    "                    reasons = \"; \".join(f\"{t['name']} ({t['rationale']})\" for t in a.fired_triggers)\n",
    "                    lines.append(f\"- {a.name}: {a.posture} due to {reasons}.\")\n",
    "        else:\n",
    "            lines.append(\"\\nRecommended Readiness Posture: Normal operations for all monitored areas.\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def generate(self, risks_msg: HazardRisksMessage, triggers_msg: TriggerResultsMessage) -> BriefPacketMessage:\n",
    "        posture_overview = {a.name: a.posture for a in triggers_msg.areas}\n",
    "        if not self.use_gemini or not GEMINI_API_KEY:\n",
    "            brief_text = self._fallback_brief_text(risks_msg, triggers_msg)\n",
    "        else:\n",
    "            structured = {\n",
    "                \"region_name\": self.region_name,\n",
    "                \"as_of\": risks_msg.as_of.isoformat(),\n",
    "                \"risks\": [asdict(r) for r in risks_msg.risks],\n",
    "                \"areas\": [\n",
    "                    {\"name\": a.name, \"posture\": a.posture, \"fired_triggers\": a.fired_triggers}\n",
    "                    for a in triggers_msg.areas\n",
    "                ],\n",
    "            }\n",
    "            prompt = (\n",
    "                \"You are generating an internal weather & hazard brief for the American Red Cross. \"\n",
    "                \"Write a concise brief for regional leadership, with sections:\\n\"\n",
    "                \"1) Overview\\n2) Key Hazards by Area\\n3) Recommended Readiness Posture\\n\\n\"\n",
    "                \"Focus on timing, likelihood, impact, and operational implications. \"\n",
    "                \"Avoid overly technical meteorological jargon. \"\n",
    "                \"Input (JSON):\\n\\n\"\n",
    "                f\"{json.dumps(structured)[:4000]}\"\n",
    "            )\n",
    "            brief_text = call_gemini(prompt)\n",
    "            if brief_text.startswith(\"[Gemini error\") or brief_text.startswith(\"[Gemini raw\"):\n",
    "                brief_text = self._fallback_brief_text(risks_msg, triggers_msg)\n",
    "        return BriefPacketMessage(\n",
    "            run_id=risks_msg.run_id,\n",
    "            as_of=risks_msg.as_of,\n",
    "            markdown_brief=brief_text,\n",
    "            text_brief=brief_text,\n",
    "            posture_overview=posture_overview,\n",
    "        )\n",
    "\n",
    "class MemoryLoggingAgent:\n",
    "    def __init__(self):\n",
    "        self.runs: List[Dict[str, Any]] = []\n",
    "        self.risks_log: List[Dict[str, Any]] = []\n",
    "        self.triggers_log: List[Dict[str, Any]] = []\n",
    "        self.briefs_log: List[Dict[str, Any]] = []\n",
    "        self.checkpoint = CheckpointState(\n",
    "            last_run_time=None,\n",
    "            last_posture_by_area={},\n",
    "            last_run_id=None,\n",
    "            operational_period_label=\"Initial\",\n",
    "        )\n",
    "\n",
    "    def log_cycle(self,\n",
    "                  hazard_inputs: HazardInputsMessage,\n",
    "                  risks_msg: HazardRisksMessage,\n",
    "                  trig_msg: TriggerResultsMessage,\n",
    "                  brief_msg: BriefPacketMessage):\n",
    "        self.runs.append({\n",
    "            \"run_id\": hazard_inputs.run_id,\n",
    "            \"as_of\": hazard_inputs.as_of,\n",
    "            \"areas\": \",\".join(hazard_inputs.areas),\n",
    "            \"n_forecasts\": len(hazard_inputs.forecasts),\n",
    "            \"n_bulletins\": len(hazard_inputs.bulletins),\n",
    "            \"n_risks\": len(risks_msg.risks),\n",
    "            \"n_trigger_areas\": len(trig_msg.areas),\n",
    "        })\n",
    "        for r in risks_msg.risks:\n",
    "            row = asdict(r)\n",
    "            row[\"run_id\"] = risks_msg.run_id\n",
    "            row[\"as_of\"] = risks_msg.as_of\n",
    "            self.risks_log.append(row)\n",
    "        for a in trig_msg.areas:\n",
    "            for t in a.fired_triggers:\n",
    "                self.triggers_log.append({\n",
    "                    \"run_id\": trig_msg.run_id,\n",
    "                    \"as_of\": trig_msg.as_of,\n",
    "                    \"area\": a.name,\n",
    "                    \"posture\": a.posture,\n",
    "                    \"trigger_id\": t[\"trigger_id\"],\n",
    "                    \"trigger_name\": t[\"name\"],\n",
    "                    \"rationale\": t[\"rationale\"],\n",
    "                })\n",
    "        self.briefs_log.append({\n",
    "            \"run_id\": brief_msg.run_id,\n",
    "            \"as_of\": brief_msg.as_of,\n",
    "            \"brief\": brief_msg.text_brief,\n",
    "        })\n",
    "        self.checkpoint = CheckpointState(\n",
    "            last_run_time=hazard_inputs.as_of,\n",
    "            last_posture_by_area=brief_msg.posture_overview,\n",
    "            last_run_id=hazard_inputs.run_id,\n",
    "            operational_period_label=\"Ongoing\",\n",
    "        )\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# GCS checkpoint helpers\n",
    "# -------------------------------------------------------\n",
    "\n",
    "def save_checkpoint_to_gcs(checkpoint: CheckpointState):\n",
    "    if not storage or not GCS_BUCKET:\n",
    "        logging.warning(\"GCS not configured; skipping checkpoint save.\")\n",
    "        return\n",
    "    client = storage.Client(project=GCP_PROJECT_ID or None)\n",
    "    bucket = client.bucket(GCS_BUCKET)\n",
    "    blob = bucket.blob(CHECKPOINT_BLOB_NAME)\n",
    "    payload = {\n",
    "        \"last_run_time\": checkpoint.last_run_time.isoformat() if checkpoint.last_run_time else None,\n",
    "        \"last_posture_by_area\": checkpoint.last_posture_by_area,\n",
    "        \"last_run_id\": checkpoint.last_run_id,\n",
    "        \"operational_period_label\": checkpoint.operational_period_label,\n",
    "    }\n",
    "    blob.upload_from_string(json.dumps(payload), content_type=\"application/json\")\n",
    "    logging.info(\"Checkpoint saved to GCS.\")\n",
    "\n",
    "def load_checkpoint_from_gcs() -> Optional[CheckpointState]:\n",
    "    if not storage or not GCS_BUCKET:\n",
    "        logging.warning(\"GCS not configured; skipping checkpoint load.\")\n",
    "        return None\n",
    "    client = storage.Client(project=GCP_PROJECT_ID or None)\n",
    "    bucket = client.bucket(GCS_BUCKET)\n",
    "    blob = bucket.blob(CHECKPOINT_BLOB_NAME)\n",
    "    if not blob.exists():\n",
    "        logging.info(\"No checkpoint in GCS.\")\n",
    "        return None\n",
    "    data = json.loads(blob.download_as_text())\n",
    "    last_run_time = dt.datetime.fromisoformat(data[\"last_run_time\"]) if data[\"last_run_time\"] else None\n",
    "    return CheckpointState(\n",
    "        last_run_time=last_run_time,\n",
    "        last_posture_by_area=data.get(\"last_posture_by_area\", {}),\n",
    "        last_run_id=data.get(\"last_run_id\"),\n",
    "        operational_period_label=data.get(\"operational_period_label\", \"Ongoing\"),\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Orchestrator + exported cycle\n",
    "# -------------------------------------------------------\n",
    "\n",
    "class OrchestratorScheduler:\n",
    "    def __init__(self,\n",
    "                 ingestion: DataIngestionAgent,\n",
    "                 hazard_int: HazardInterpretationAgent,\n",
    "                 trigger_eval: TriggerEvaluationAgent,\n",
    "                 briefing: BriefingAgent,\n",
    "                 memory: MemoryLoggingAgent):\n",
    "        self.ingestion = ingestion\n",
    "        self.hazard_int = hazard_int\n",
    "        self.trigger_eval = trigger_eval\n",
    "        self.briefing = briefing\n",
    "        self.memory = memory\n",
    "        self.paused = False\n",
    "\n",
    "    def run_cycle(self,\n",
    "                  time_window: str = \"next_72_hours\",\n",
    "                  products: Optional[List[str]] = None,\n",
    "                  demo_force_hazard: bool = False):\n",
    "        if self.paused:\n",
    "            logging.info(\"Orchestrator paused; skipping cycle.\")\n",
    "            return None\n",
    "        hazard_inputs_msg = self.ingestion.ingest(\n",
    "            time_window=time_window,\n",
    "            products=products,\n",
    "            demo_force_hazard=demo_force_hazard,\n",
    "        )\n",
    "        risks_msg = self.hazard_int.assess(hazard_inputs_msg)\n",
    "        trig_msg = self.trigger_eval.evaluate(risks_msg)\n",
    "        brief_msg = self.briefing.generate(risks_msg, trig_msg)\n",
    "        self.memory.log_cycle(hazard_inputs_msg, risks_msg, trig_msg, brief_msg)\n",
    "        return hazard_inputs_msg, risks_msg, trig_msg, brief_msg\n",
    "\n",
    "\n",
    "# Instantiate global agents + orchestrator for deployment\n",
    "ingestion_agent = DataIngestionAgent(REGION_AREAS)\n",
    "hazard_agent = HazardInterpretationAgent(use_gemini=False)\n",
    "trigger_agent = TriggerEvaluationAgent(TRIGGERS)\n",
    "briefing_agent = BriefingAgent(REGION_NAME, use_gemini=True)\n",
    "memory_agent = MemoryLoggingAgent()\n",
    "\n",
    "orchestrator = OrchestratorScheduler(\n",
    "    ingestion=ingestion_agent,\n",
    "    hazard_int=hazard_agent,\n",
    "    trigger_eval=trigger_agent,\n",
    "    briefing=briefing_agent,\n",
    "    memory=memory_agent,\n",
    ")\n",
    "\n",
    "def orchestrator_cloud_run_cycle():\n",
    "    \"\"\"\n",
    "    Core monitoring cycle for Cloud Run / Scheduler:\n",
    "    - Load checkpoint\n",
    "    - Run one cycle\n",
    "    - Save checkpoint\n",
    "    \"\"\"\n",
    "    cp = load_checkpoint_from_gcs()\n",
    "    if cp:\n",
    "        memory_agent.checkpoint = cp\n",
    "    result = orchestrator.run_cycle()\n",
    "    if result is None:\n",
    "        return \"SKIPPED\"\n",
    "    save_checkpoint_to_gcs(memory_agent.checkpoint)\n",
    "    return \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a962fd25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:30.673001Z",
     "iopub.status.busy": "2025-11-27T05:20:30.672692Z",
     "iopub.status.idle": "2025-11-27T05:20:30.679557Z",
     "shell.execute_reply": "2025-11-27T05:20:30.678623Z"
    },
    "papermill": {
     "duration": 0.026699,
     "end_time": "2025-11-27T05:20:30.681321",
     "exception": false,
     "start_time": "2025-11-27T05:20:30.654622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "# ===== main.py (FastAPI wrapper for Cloud Run) =====\n",
    "\"\"\"\n",
    "HTTP wrapper around orchestrator_cloud_run_cycle().\n",
    "\n",
    "- GET \"/\"   → healthcheck\n",
    "- POST \"/run\" → run one monitoring cycle (for Cloud Scheduler)\n",
    "\"\"\"\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import JSONResponse\n",
    "\n",
    "from agents import orchestrator_cloud_run_cycle\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"Weather & Hazard Sentinel\",\n",
    "    description=\"Red Cross Weather & Hazard Monitoring Orchestrator\",\n",
    "    version=\"1.0.0\",\n",
    ")\n",
    "\n",
    "@app.get(\"/\")\n",
    "def healthcheck():\n",
    "    return {\"status\": \"ok\", \"service\": \"weather-hazard-sentinel\"}\n",
    "\n",
    "@app.post(\"/run\")\n",
    "def run_cycle():\n",
    "    try:\n",
    "        result = orchestrator_cloud_run_cycle()\n",
    "        return JSONResponse(status_code=200, content={\"status\": \"ok\", \"result\": result})\n",
    "    except Exception as e:\n",
    "        return JSONResponse(status_code=500, content={\"status\": \"error\", \"detail\": str(e)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c43ef2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T05:20:30.704796Z",
     "iopub.status.busy": "2025-11-27T05:20:30.704215Z",
     "iopub.status.idle": "2025-11-27T05:20:30.710557Z",
     "shell.execute_reply": "2025-11-27T05:20:30.709688Z"
    },
    "papermill": {
     "duration": 0.019696,
     "end_time": "2025-11-27T05:20:30.712173",
     "exception": false,
     "start_time": "2025-11-27T05:20:30.692477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "# ===== Dockerfile (for Cloud Run deployment) =====\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Install system deps (if needed)\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "    build-essential \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Copy Python files\n",
    "COPY agents.py main.py ./ \n",
    "\n",
    "# Install Python dependencies\n",
    "RUN pip install --no-cache-dir \\\n",
    "    fastapi \\\n",
    "    uvicorn[standard] \\\n",
    "    google-generativeai \\\n",
    "    google-cloud-storage \\\n",
    "    requests \\\n",
    "    pandas\n",
    "\n",
    "# Environment variables (Cloud Run can override)\n",
    "ENV PORT=8080\n",
    "EXPOSE 8080\n",
    "\n",
    "# Start the FastAPI app\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.193979,
   "end_time": "2025-11-27T05:20:33.615105",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-27T05:19:47.421126",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
